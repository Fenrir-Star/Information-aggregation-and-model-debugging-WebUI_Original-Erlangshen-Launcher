标题,作者,摘要,关键词
文本生成领域的深度强化学习研究进展,"徐聪,李擎,张德政,陈鹏,崔家瑞",谷歌的人工智能系统（AlphaGo）在围棋领域取得了一系列成功，使得深度强化学习得到越来越多的关注。深度强化学习融合了深度学习对复杂环境的感知能力和强化学习对复杂情景的决策能力。而自然语言处理过程中有着数量巨大的词汇或者语句需要表征，并且在对话系统、机器翻译和图像描述等文本生成任务中存在大量难以建模的决策问题。这使得深度强化学习在自然语言处理的文本生成任务中能够发挥重要的作用，帮助改进现有的模型结构或者训练机制，并且已经取得了很多显著的成果。为此，本文系统阐述深度强化学习应用在不同的文本生成任务中的一些主要方法，梳理其发展的轨迹，分析算法特点。最后，展望深度强化学习与自然语言处理任务融合的前景和挑战。,"深度强化学习,自然语言处理,文本生成,对话系统,机器翻译,图像描述"
大语言模型研究现状与趋势,"王耀祖,李擎,戴张杰,徐越",在过去20年中，语言建模（Language models，LM）已经成为一种主要方法，用于语言理解和生成，同时作为自然语言处理（Natural language processing，NLP）领域下游的关键技术受到广泛关注. 近年来，大语言模型（Large language models，LLMs），例如ChatGPT等技术，取得了显著进展，对人工智能乃至其他领域的变革和发展产生了深远的影响. 鉴于LLMs迅猛的发展，本文首先对LLMs相关技术架构和模型规模等方面的演进历程进行了全面综述，总结了模型训练方法、优化技术以及评估手段. 随后，分析了LLMs在教育、医疗、金融、工业等领域的应用现状，同时讨论了它们的优势和局限性. 此外，还探讨了大语言模型针对社会伦理、隐私和安全等方面引发的安全性与一致性问题及技术措施. 最后，展望了大语言模型未来的研究趋势，包括模型的规模与效能、多模态处理、社会影响等方面的发展方向. 本文通过全面分析当前研究状况和未来走向，旨在为研究者提供关于大语言模型的深刻见解和启发，以推动该领域的进一步发展.,"大语言模型(LLMs),自然语言处理,深度学习,人工智能,ChatGPT"
多语言机译系统中高质量语义单元库形成方法,"胡玥,高小宇,高庆狮","讨论构建多自然语言互译机译系统所需的高质量、可扩充、完备的、无可弃、无重复、无非正常歧义的多语统一语义单元知识库.在构建过程中采用类型特征分类方法有效降低计算复杂性,使去重复的计算量降低一半,去可弃的计算量降到O(βN)(N是语义单元库规模,β是有界数,β<C,C是常数).全部算法都可以在多核处理机上以常数效率地实现.同时讨论了语义单元的再分解和自然语言种类的增多时语义单元知识库的扩充方法.该知识库不仅用于多自然语言互译系统,还可作为自然语言理解和处理的基础知识库.","自然语言处理系统,自然语言,机器翻译,语义单元"
人才资源智能管理系统的设计,"丁左,田战强,张杰","以冶金工业部人才资源的管理问题为背景,给出了人才资源智能管理系统的具体设计方法.该系统中,广义的管理分析预测模型树用于其知识表达,系统结构由多库结构支持;在其推理机方面,应用元知识推理以协调定性推理、定量推理和人工神经网络推理.将有限的自然语言理解引入人-机界面,用TURBO PROLOG和C语言在IBM/AT微机上对该设计部分实现,表明了其合理性及可行性.","人工智能,管理/人才资源,智能管理系统"
基于ALBERT与双向GRU的中医脏腑定位模型,"张德政,范欣欣,谢永红,蒋彦钊",脏腑定位，即明确病变所在的脏腑，是中医脏腑辨证的重要阶段。本文旨在通过神经网络模型搭建中医脏腑定位模型，输入症状文本信息，输出对应的病变脏腑标签，为实现中医辅助诊疗的脏腑辨证提供支持。将中医的脏腑定位问题建模为自然语言处理中的多标签文本分类问题，基于中医的医案数据，提出一种基于预训练模型ALBERT和双向门控循环单元（Bi-GRU）的脏腑定位模型。对比实验和消融实验的结果表明，本文提出的方法在中医脏腑定位的问题上相比于多层感知机模型、决策树模型具有更高的准确性，与Word2Vec文本表示方法相比，本文使用的ALBERT预训练模型的文本表示方法有效提升了模型的准确率。在模型参数上，ALBERT预训练模型相比BERT模型降低了模型参数量，有效减小了模型大小。最终，本文提出的脏腑定位模型在测试集上F1值达到了0.8013。,"多标签文本分类,ALBERT,门控循环单元,脏腑定位,中医"
深度神经网络模型压缩综述,"李江昀,赵义凯,薛卓尔,蔡铮,李擎",深度神经网络近年在计算机视觉以及自然语言处理等任务上不断刷新已有最好性能，已经成为最受关注的研究方向.深度网络模型虽然性能显著，但由于参数量巨大、存储成本与计算成本过高，仍然难以部署到硬件受限的嵌入式或移动设备上.相关研究发现，基于卷积神经网络的深度模型本身存在参数冗余，模型中存在对最终结果无用的参数，这为深度网络模型压缩提供了理论支持.因此，如何在保证模型精度条件下降低模型大小已经成为热点问题.本文对国内外学者近几年在模型压缩方面所取得的成果与进展进行了分类归纳并对其优缺点进行评价，并探讨了模型压缩目前存在的问题以及未来的发展方向.,"深度神经网络,模型压缩,深度学习,网络剪枝,网络蒸馏"
基于文本语料的涉恐事件实体属性抽取,"曹文斌,武卓峰,杨涛,凡友荣",基于语义角色分析，提出了一种三元组涉恐事件实体属性抽取方法，为网络空间涉恐活动的监测及预警提供技术支持。首先，基于西北政法大学“反恐怖主义信息网”文本语料数据进行数据采集和清洗等预处理工作，采用朴素贝叶斯文本分类算法识别涉恐事件文本，并采用关键词提取算法TF-IDF（Term frequency-inverse document frequency，词频-逆文档频率）构建涉恐专有词库，结合自然语言处理技术构建带词性的涉恐专有词库。然后通过语义角色分析、句法依存分析，提取了主语谓语宾语关系、定语后置动宾关系、人名//地名//机构和介宾关系主谓动补4类涉恐三元组结构。最后，利用正则表达式及带词性的涉恐专有名词分析，在4类三元组短文本中提取出恐怖事件发生时间、发生地点、伤亡情况、攻击方式、武器类型和恐怖组织6类实体属性。对采集的4221篇文章数据进行实验分析，6类实体属性抽取的测评结果F1值均超过80%，对网络空间的涉恐事件监测及预警，维护社会公共安全具有重要现实意义。,"实体抽取,语义角色分析,三元组,朴素贝叶斯,文本分类"
深度神经网络模型量化方法综述,"杨春,张睿尧,黄泷,遆书童,林金辉,董志伟,陈松路,刘艳,殷绪成",近年来，利用大型预训练模型来提高深度神经网络在计算机视觉以及自然语言处理等具体任务下的泛化能力和性能，逐渐成为基于深度学习的人工智能技术与应用的发展趋势. 虽然这些深度神经网络模型表现优异，但是由于模型的结构复杂、参数量庞大与计算成本极高，使得它们仍然难以被部署在如家电或智能手机等资源受限的边缘及端侧硬件平台上，这很大程度上阻碍了人工智能技术的应用. 因此，模型压缩与加速技术一直都是深度神经网络模型大规模商业化应用推广的关键问题之一. 当前在多种模型压缩与加速方案中，模型量化是其中主要的有效方法之一. 模型量化技术可以通过减少深度神经网络模型参数的位宽和中间过程特征图的位宽，从而达到压缩加速深度神经网络的目的，使量化后的网络能够部署在资源有限的边缘设备上，然而，由于量化会导致信息的大量丢失，如何在保证模型任务精度条件下实现模型量化已经成为热点问题. 另外，因硬件设备以及应用场景的不同，模型量化技术已经发展成为一个多分支的研究问题. 通过全面地调研不同角度下模型量化相关技术现状，并且深入地总结归纳不同方法的优缺点，可以发现量化技术目前仍然存在的问题，并为未来可能的发展指明方向.,"深度神经网络,模型压缩与加速,模型量化,量化感知训练,后训练量化,混合精度量化"
基于深层特征抽取的日文词义消歧系统,"雷雪梅,王大亮,田中贵秋,曾广平","词义消歧的特征来源于上下文.日文兼有中英文的语言特性,特征抽取更为复杂.针对日文特点,在词义消歧逻辑模型基础上,利用最大熵模型优良的信息融合性能,采用深层特征抽取方法,引入语义、句法类特征用于消解歧义.同时,为避免偏斜指派,采用BeamSearch算法进行词义序列标注.实验结果表明,与仅使用表层词法类特征方法相比,本文构造的日文词义消歧系统的消歧精度提高2%～3%,动词消歧精度获得5%的改善.","自然语言处理,词义消歧,最大熵模型,特征抽取"
嵌入共识知识的因果图文检索方法,"梁彦鹏,刘雪儿,马忠贵,李卓",跨模态图像−文本检索是一项在给定一种模态（如文本）的查询条件下检索另一种模态（如图像）的任务. 该任务的关键问题在于如何准确地测量图文两种模态之间的相似性，在减少视觉和语言这两种异构模态之间的视觉语义差异中起着至关重要的作用. 传统的检索范式依靠深度学习提取图像和文本的特征表示，并将其映射到一个公共表示空间中进行匹配. 然而，这种方法更多地依赖数据表面的相关关系，无法挖掘数据背后真实的因果关系，在高层语义信息的表示和可解释性方面面临着挑战. 为此，在深度学习的基础上引入因果推断和嵌入共识知识，提出嵌入共识知识的因果图文检索方法. 具体而言，将因果干预引入视觉特征提取模块，通过因果关系替换相关关系学习常识因果视觉特征，并与原始视觉特征进行连接得到最终的视觉特征表示. 为解决本方法文本特征表示不足的问题，采用更强大的文本特征提取模型BERT（Bidirectional encoder representations from transformers，双向编码器表示），并且嵌入两种模态数据之间共享的共识知识对图文特征进行共识级的表示学习. 在MS-COCO数据集以及MS-COCO 到Flickr30k上的跨数据集实验，证明了本文方法可以在双向图文检索任务上实现召回率和平均召回率的一致性改进.,"因果推断,图像−文本检索,跨模态,计算机视觉,自然语言处理"
基于Zero-Shot-CoT的对话价值观优先级标注方法,"马志强(通讯作者), 刘佳, 李鑫, 王奎波, 刘义兴, 叶浩然",价值观优先级识别旨在识别文本背后隐含的价值观优先级属性，从而判断其是否与特定的价值观及其类型相符，对于用户语言检测、评估大语言模型生成内容和探究大语言模型对人类价值观优先级的评估能力至关重要。目前，由于缺乏对话场景下的人类价值观识别数据集，在对话中建模并识别人类价值观优先级的研究仍未被触及。因此，构建高质量的对话价值观优先级识别数据集是首要任务。然而，标注对话价值观优先级识别数据集要求标注者具备一定专业知识储备，标注门槛较高，因此，本文基于大语言模型对现有的对话语料进行标注，提供了一个对话价值观优先级识别数据集的标注案例，扩展了基于大语言模型的数据标注的应用。具体来说，我们设计了一种基于Zero-Shot-CoT的对话价值观标注方法，模拟了人类标注结果，并通过本文提出的对话价值观优先级标注方法，构建了一个大规模对话价值观识别数据集ValueCon。有效性实验结果表明，与人工标注的数据集相比，ValueCon数据集能够更有效的训练并提升模型性能。,"数据标注,大语言模型,价值观计算,人工智能伦理,自然语言处理"
