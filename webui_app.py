# ===================== é…ç½®æ—¥å¿— =====================
import logging
# 1. è·å–PyTorchåˆ†å¸ƒå¼é‡å®šå‘æ¨¡å—çš„æ—¥å¿—å™¨
logger = logging.getLogger("torch.distributed.elastic.multiprocessing.redirects")
# 2. å°†è¯¥æ—¥å¿—å™¨çš„çº§åˆ«è®¾ä¸ºERRORï¼ˆä»…è¾“å‡ºé”™è¯¯ï¼Œå±è”½WARNINGåŠä»¥ä¸‹æ—¥å¿—ï¼‰
logger.setLevel(logging.ERROR)
# 3. ç¦æ­¢æ—¥å¿—ä¼ æ’­åˆ°çˆ¶æ—¥å¿—å™¨ï¼ˆé¿å…å…¶ä»–åœ°æ–¹é‡å¤è¾“å‡ºï¼‰
logger.propagate = False

# ===================== è­¦å‘Šè¿‡æ»¤ =====================
import warnings
warnings.filterwarnings(
    "ignore",
    message="NOTE: Redirects are currently not supported in Windows or MacOs.",
    category=UserWarning,
    module="torch.distributed.elastic.multiprocessing.redirects"
)

import gradio as gr
import os
import re
import sys
import subprocess
import time
import csv # å¯¼å…¥ csv åº“ç”¨äºè¯»å–å’Œå†™å…¥æ•°æ®
import glob # å¯¼å…¥ glob ç”¨äºæ–‡ä»¶æœç´¢
import traceback # å¯¼å…¥ traceback ç”¨äºé”™è¯¯è°ƒè¯•

# ===================== æ¨¡å‹ä¾èµ–å’Œåˆå§‹åŒ–ï¼ˆçœŸå®ä»£ç ç»“æ„ï¼‰=====================
try:
    import torch
    from transformers import BertTokenizer, MegatronBertModel, MegatronBertConfig
    import torch.nn.functional as F
    
    # å®šä¹‰ quick_start.py ä¸­ä½¿ç”¨çš„æ ‡ç­¾æ˜ å°„
    # TNEWS (æ–°é—»åˆ†ç±»)
    TNEWS_LABELS = {
        0: "ç§‘æŠ€", 1: "å¨±ä¹", 2: "ä½“è‚²", 3: "è´¢ç»", 4: "æ—¶æ”¿", 5: "æ•™è‚²",
        6: "å†›äº‹", 7: "æ±½è½¦", 8: "æˆ¿äº§", 9: "æ¸¸æˆ", 10: "æ—¶å°š", 11: "å½©ç¥¨",
        12: "è‚¡ç¥¨", 13: "å®¶å±…", 14: "ç¤¾ä¼š"
    }
    
    # OCNLI (è‡ªç„¶è¯­è¨€æ¨ç†)
    OCNLI_LABELS = {0: "è•´å«", 1: "çŸ›ç›¾", 2: "ä¸­ç«‹"}
    
    # CSLDCP (ä¸»é¢˜æ–‡çŒ®åˆ†ç±»)
    CSLDCP_LABELS = {
        0: "è®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯", 1: "ç”µå­ç§‘å­¦ä¸æŠ€æœ¯", 2: "ä¿¡æ¯ä¸é€šä¿¡å·¥ç¨‹", 3: "æ§åˆ¶ç§‘å­¦ä¸å·¥ç¨‹",
        4: "è½¯ä»¶å·¥ç¨‹", 5: "ç½‘ç»œç©ºé—´å®‰å…¨", 6: "æ•°å­¦", 7: "ç‰©ç†å­¦", 8: "åŒ–å­¦", 9: "ç”Ÿç‰©å­¦",
        10: "åŒ»å­¦", 11: "ç®¡ç†å­¦", 12: "ç»æµå­¦", 13: "æ³•å­¦", 14: "æ•™è‚²å­¦", 15: "æ–‡å­¦",
        16: "å†å²å­¦", 17: "å“²å­¦", 18: "è‰ºæœ¯å­¦", 19: "å†œå­¦", 20: "å·¥å­¦", 21: "ç†å­¦",
        22: "åŒ»å­¦æŠ€æœ¯", 23: "å…¬å…±å«ç”Ÿä¸é¢„é˜²åŒ»å­¦", 24: "è¯å­¦", 25: "ä¸­è¯å­¦", 26: "å£è…”åŒ»å­¦",
        27: "ä¸´åºŠåŒ»å­¦", 28: "æŠ¤ç†å­¦", 29: "åŸºç¡€åŒ»å­¦", 30: "ä¸­åŒ»å­¦", 31: "ä¸­è¥¿åŒ»ç»“åˆ",
        32: "ç®¡ç†ç§‘å­¦ä¸å·¥ç¨‹", 33: "å·¥å•†ç®¡ç†", 34: "å…¬å…±ç®¡ç†", 35: "å›¾ä¹¦æƒ…æŠ¥ä¸æ¡£æ¡ˆç®¡ç†",
        36: "åº”ç”¨ç»æµå­¦", 37: "ç†è®ºç»æµå­¦", 38: "ç»Ÿè®¡å­¦", 39: "æ³•å­¦ç†è®º", 40: "å®ªæ³•å­¦ä¸è¡Œæ”¿æ³•å­¦",
        41: "åˆ‘æ³•å­¦", 42: "æ°‘å•†æ³•å­¦", 43: "è¯‰è®¼æ³•å­¦", 44: "ç»æµæ³•å­¦", 45: "ç¯å¢ƒä¸èµ„æºä¿æŠ¤æ³•å­¦",
        46: "å›½é™…æ³•å­¦", 47: "å†›äº‹æ³•å­¦", 48: "æ•™è‚²å­¦åŸç†", 49: "è¯¾ç¨‹ä¸æ•™å­¦è®º", 50: "å­¦å‰æ•™è‚²å­¦",
        51: "é«˜ç­‰æ•™è‚²å­¦", 52: "æˆäººæ•™è‚²å­¦", 53: "èŒä¸šæŠ€æœ¯æ•™è‚²å­¦", 54: "ç‰¹æ®Šæ•™è‚²å­¦", 55: "æ•™è‚²æŠ€æœ¯å­¦",
        56: "ä¸­å›½è¯­è¨€æ–‡å­¦", 57: "å¤–å›½è¯­è¨€æ–‡å­¦", 58: "æ–°é—»ä¼ æ’­å­¦", 59: "è‰ºæœ¯å­¦ç†è®º", 60: "éŸ³ä¹ä¸èˆè¹ˆå­¦",
        61: "æˆå‰§ä¸å½±è§†å­¦", 62: "ç¾æœ¯å­¦", 63: "è®¾è®¡å­¦", 64: "å†å²å­¦ç†è®º", 65: "ä¸­å›½å²",
        66: "ä¸–ç•Œå²"
    }
    
    # IFLYTEK (åº”ç”¨æè¿°åˆ†ç±»)
    IFLYTEK_LABELS = {
        0: "æ‰“è½¦", 1: "åœ°å›¾å¯¼èˆª", 2: "æ—…æ¸¸", 3: "å¤–å–", 4: "ç¾é£Ÿ", 5: "ç¤¾äº¤", 6: "è´­ç‰©",
        7: "è§†é¢‘", 8: "éŸ³ä¹", 9: "æ•™è‚²", 10: "åŠå…¬", 11: "å·¥å…·", 12: "é‡‘è", 13: "åŒ»ç–—å¥åº·",
        14: "å‡ºè¡Œ", 15: "æˆ¿äº§", 16: "æ‹›è˜", 17: "å°è¯´", 18: "èµ„è®¯", 19: "æ‘„å½±", 20: "ç¾å›¾",
        21: "æ¯å©´", 22: "è¿åŠ¨", 23: "ç¾å¦†", 24: "ä¸¤æ€§", 25: "åŠ¨æ¼«", 26: "æ¸¸æˆ", 27: "å¨±ä¹",
        28: "å½±è§†", 29: "æ˜Ÿåº§", 30: "ç›´æ’­", 31: "ç†è´¢", 32: "ä¿é™©", 33: "è´·æ¬¾", 34: "ä¿¡ç”¨å¡",
        35: "è¯åˆ¸", 36: "è‚¡ç¥¨", 37: "åŸºé‡‘", 38: "é“¶è¡Œ", 39: "æ”¯ä»˜", 40: "è®°è´¦", 41: "ç¨åŠ¡",
        42: "ç¤¾ä¿", 43: "åŒ»ä¿", 44: "åŒ»ç–—æœåŠ¡", 45: "å¥åº·ç®¡ç†", 46: "å°±åŒ»æŒ‚å·", 47: "è¯å“æŸ¥è¯¢",
        48: "ä½“æ£€", 49: "å…»ç”Ÿ", 50: "å‡è‚¥", 51: "è‚²å„¿", 52: "æ—©æ•™", 53: "K12æ•™è‚²", 54: "èŒä¸šæ•™è‚²",
        55: "è¯­è¨€å­¦ä¹ ", 56: "è€ƒç ”", 57: "å…¬è€ƒ", 58: "ç•™å­¦", 59: "æ±‚èŒ", 60: "èŒåœº", 61: "åŠå…¬åä½œ",
        62: "æ–‡æ¡£ç®¡ç†", 63: "ç¬”è®°", 64: "æ€ç»´å¯¼å›¾", 65: "PPT", 66: "è¡¨æ ¼", 67: "PDF", 68: "OCR",
        69: "ç¿»è¯‘", 70: "è¯å…¸", 71: "è®¡ç®—å™¨", 72: "æ—¥å†", 73: "å¤©æ°”", 74: "é—¹é’Ÿ", 75: "æ‰‹ç”µç­’",
        76: "æ–‡ä»¶ç®¡ç†", 77: "å‹ç¼©", 78: "åŠ å¯†", 79: "æ€æ¯’", 80: "æµè§ˆå™¨", 81: "è¾“å…¥æ³•", 82: "å£çº¸",
        83: "ä¸»é¢˜", 84: "é“ƒå£°", 85: "æ–‡ä»¶ä¼ è¾“", 86: "WiFi", 87: "è“ç‰™", 88: "æŠ•å±", 89: "è¿œç¨‹æ§åˆ¶",
        90: "æ™ºèƒ½å®¶å±…", 91: "æ±½è½¦æœåŠ¡", 92: "è¿ç« æŸ¥è¯¢", 93: "é©¾æ ¡", 94: "æ±½è½¦èµ„è®¯", 95: "äºŒæ‰‹è½¦",
        96: "ç§Ÿæˆ¿", 97: "ä¹°æˆ¿", 98: "è£…ä¿®", 99: "å®¶å±…å»ºæ", 100: "å®¶æ”¿", 101: "å¿«é€’", 102: "ç‰©æµ",
        103: "å¤–å–é…é€", 104: "é¤é¥®æœåŠ¡", 105: "é…’åº—é¢„è®¢", 106: "æœºç¥¨", 107: "ç«è½¦ç¥¨", 108: "ç§Ÿè½¦",
        109: "å…±äº«å•è½¦", 110: "å…¬äº¤", 111: "åœ°é“", 112: "è½®æ¸¡", 113: "é•¿é€”å®¢è¿", 114: "åœè½¦åœº",
        115: "åŠ æ²¹", 116: "æ´—è½¦", 117: "æ±½è½¦ç»´ä¿®", 118: "å…¶ä»–"
    }

except ImportError as e:
    print(f"âš ï¸ è­¦å‘Š: ç¼ºå°‘ PyTorch/Transformers ä¾èµ–ã€‚æ¨¡å‹åŠŸèƒ½å°†æ— æ³•å®é™…è¿è¡Œã€‚é”™è¯¯: {e}")
    # å®šä¹‰å ä½ç¬¦ä»¥é˜²æ­¢ä»£ç å´©æºƒ
    class MockTokenizer:
        def __init__(self, *args, **kwargs): pass
        def __call__(self, *args, **kwargs): return {"input_ids": torch.tensor([[1, 103, 1]]), "token_type_ids": torch.tensor([[0, 0, 0]]), "attention_mask": torch.tensor([[1, 1, 1]])}
        def encode(self, *args, **kwargs): return torch.tensor([[1, 103, 1]])
        def decode(self, *args, **kwargs): return ""
    class MockModel:
        def __init__(self, *args, **kwargs): pass
        def to(self, *args, **kwargs): return self
        def eval(self): pass
        def device(self): return "cpu"
        def __call__(self, *args, **kwargs): 
            # æ¨¡æ‹Ÿè¾“å‡ºï¼Œè‡³å°‘åŒ…å«ä¸€ä¸ª [CLS] ç‰¹å¾
            hidden_state = torch.rand(1, 128, 768) 
            pooler_output = hidden_state[:, 0, :]
            return (hidden_state, pooler_output) # æ¨¡æ‹Ÿè¾“å‡º (last_hidden_state, pooler_output)
    
    torch = None
    BertTokenizer = MockTokenizer
    MegatronBertModel = MockModel
    MegatronBertConfig = lambda *args, **kwargs: None
    F = None
    TNEWS_LABELS = OCNLI_LABELS = CSLDCP_LABELS = IFLYTEK_LABELS = {}


# ====================================================================
# 1. è·¯å¾„å’Œå·¥å…·å‡½æ•° 
# ====================================================================

# å‡è®¾ app.py ä½äº Program/ ç›®å½•ä¸‹
CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))
MODEL_BASE_DIR = os.path.join(CURRENT_DIR, "Models")
DATA_BASE_DIR = os.path.join(CURRENT_DIR, "Spiders", "Information")


# --- åŠ¨æ€æ‰«æ Spiders æ–‡ä»¶å¤¹ ---
def get_available_spiders() -> list:
    """æ‰«æ Spiders/AllSpider/ ä¸‹çš„æ‰€æœ‰ .py æ–‡ä»¶ä½œä¸ºå¯ç”¨çˆ¬è™«"""
    SPIDERS_DIR = os.path.join(CURRENT_DIR, "Spiders", "AllSpider")
    if not os.path.exists(SPIDERS_DIR):
        print(f"âš ï¸ è­¦å‘Š: çˆ¬è™«åŸºç¡€è·¯å¾„ä¸å­˜åœ¨: {SPIDERS_DIR}")
        return []
    
    # æŸ¥æ‰¾æ‰€æœ‰ .py æ–‡ä»¶å
    spider_files = [
        f for f in os.listdir(SPIDERS_DIR) 
        if f.endswith('.py') and not f.startswith('_') # è¿‡æ»¤æ‰é.pyæ–‡ä»¶å’Œ_å¼€å¤´çš„æ–‡ä»¶
    ]
    # å¯é€‰ï¼šå®šä¹‰æ¯ä¸ªè„šæœ¬çš„è¾“å…¥ç±»å‹ï¼ˆç”¨äºæ§åˆ¶ UI ç»„ä»¶çš„å¯è§æ€§/å€¼ï¼‰
    SPIDER_CONFIG = {
        "baidu_news_spider.py": {"sort": True, "pages": False, "default_kw": "ç‰¹æœ—æ™®", "default_sort": "1. æŒ‰ç„¦ç‚¹æ’åº"},
        "lenovo_app_spider.py": {"sort": False, "pages": True, "default_kw": "ç”µè„‘ç®¡å®¶", "default_pages": 3},
        "research_paper_spider.py": {"sort": False, "pages": True, "default_kw": "å·ç§¯", "default_pages": 2},
    }
    
    return spider_files, SPIDER_CONFIG

# è·å–é…ç½® (å¯ä¾›åç»­é€šç”¨å‡½æ•°ä½¿ç”¨)
SPIDER_FILES, SPIDER_CONFIG = get_available_spiders()


# --- æ’åºæ–¹å¼æ˜ å°„ ---
SORT_MAP = {
    "é»˜è®¤æ’åº": "0",
    "æ—¶é—´æ’åº": "2", 
    "ç„¦ç‚¹æ’åº": "1", # ç™¾åº¦æ–°é—»ä¸­ 1=ç„¦ç‚¹, 2=æ—¶é—´
    "åç§°æ’åº": "3", # å ä½ç¬¦
}
SORT_CHOICES = list(SORT_MAP.keys())


# --- åŠ¨æ€æ‰«æ Models æ–‡ä»¶å¤¹ ---
def get_available_models() -> list:
    """æ‰«æ MODEL_BASE_DIR ä¸‹çš„æ‰€æœ‰å­æ–‡ä»¶å¤¹ä½œä¸ºå¯ç”¨æ¨¡å‹"""
    if not os.path.exists(MODEL_BASE_DIR):
        print(f"âš ï¸ è­¦å‘Š: æ¨¡å‹åŸºç¡€è·¯å¾„ä¸å­˜åœ¨: {MODEL_BASE_DIR}")
        return []
    
    # è¿‡æ»¤æ‰éæ–‡ä»¶å¤¹é¡¹ï¼Œå¹¶è·å–æ–‡ä»¶å¤¹åç§°
    model_dirs = [
        d for d in os.listdir(MODEL_BASE_DIR) 
        if os.path.isdir(os.path.join(MODEL_BASE_DIR, d)) and not d.startswith('.')
    ]
    # ä¼˜å…ˆå°† 'Erlangshen' å¼€å¤´çš„æ¨¡å‹æ’åœ¨å‰é¢
    model_dirs.sort(key=lambda x: (not x.startswith('Erlangshen'), x))
    
    return model_dirs


# --- æ‰¹é‡ä»»åŠ¡æ‰€éœ€åˆ—åæ˜ å°„ (ç”¨äºæŒ‰åˆ—è¯»å– CSV) ---
TASK_COLUMN_MAP = {
    "æ–°é—»åˆ†ç±»ï¼ˆTNEWSï¼‰": {"input": "æ ‡é¢˜"},
    "æ‘˜è¦å…³é”®è¯éªŒè¯ï¼ˆCSLï¼‰": {"input": "æ‘˜è¦", "true_value": "å…³é”®è¯"},
    "ä¸»é¢˜æ–‡çŒ®åˆ†ç±»ï¼ˆCSLDCPï¼‰": {"input": "æ‘˜è¦"},
    "åº”ç”¨æè¿°åˆ†ç±»ï¼ˆIFLYTEKï¼‰": {"input": "åº”ç”¨ç®€ä»‹"},
}

def find_column_indices(header: list, required_columns: dict) -> tuple:
    """æ ¹æ® Header æŸ¥æ‰¾æ‰€éœ€åˆ—åçš„ç´¢å¼•"""
    header_map = {col.strip(): idx for idx, col in enumerate(header)}
    indices = {}
    missing = []
    
    for key, col_name in required_columns.items():
        if col_name in header_map:
            indices[key] = header_map[col_name]
        else:
            missing.append(col_name)
    return indices, missing

# --- quick_start.py æ ¸å¿ƒé›¶æ ·æœ¬åˆ†ç±»é€»è¾‘ ---
def predict_by_similarity(model, tokenizer, device, text_feat, label_map):
    """
    åŸç†ï¼šè®¡ç®—[è¾“å…¥æ–‡æœ¬ç‰¹å¾]ä¸[ç±»åˆ«åç§°ç‰¹å¾]çš„ä½™å¼¦ç›¸ä¼¼åº¦è¿›è¡Œåˆ†ç±»
    """
    label_texts = [f"å…³äº{label}çš„å†…å®¹" for label in label_map.values()]

    label_encoded = tokenizer(
        label_texts,
        return_tensors="pt",
        padding=True,
        truncation=True,
        max_length=32
    ).to(device)

    with torch.no_grad():
        label_outputs = model(** label_encoded)
        label_feats = label_outputs.pooler_output 

    text_feat_norm = F.normalize(text_feat, p=2, dim=1)
    label_feats_norm = F.normalize(label_feats, p=2, dim=1)

    # ç›¸ä¼¼åº¦çŸ©é˜µ (1, N)
    similarities = torch.mm(text_feat_norm, label_feats_norm.T)

    # ä¹˜ä»¥ä¸€ä¸ªç¼©æ”¾å› å­(scale)è®©softmaxåˆ†å¸ƒæ›´å°–é”
    logits = similarities * 15 
    pred_probs = F.softmax(logits, dim=1).cpu().numpy()[0]
    pred_idx = int(torch.argmax(logits).item())
    
    # è¿”å›æ‰€æœ‰ç›¸ä¼¼åº¦ï¼Œç”¨äºå±•ç¤ºæ‰€æœ‰ç±»åˆ«çš„ç½®ä¿¡åº¦
    all_similarities = similarities.cpu().numpy()[0] 
    
    return pred_idx, pred_probs, pred_probs[pred_idx], all_similarities 

# --- çˆ¬è™«è¿è¡Œå‡½æ•° (ä¿æŒä¸å˜) ---
def run_external_script(script_path, inputs_list: list) -> str:
    # ... (ä¸ä¹‹å‰ç‰ˆæœ¬ç›¸åŒï¼Œç”¨äºè¿è¡Œçˆ¬è™«) ...
    if not os.path.exists(script_path):
        return f"âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ°è„šæœ¬æ–‡ä»¶: {os.path.basename(script_path)}\nè¯·ç¡®ä¿æ–‡ä»¶ä½äº: {script_path}"
    
    stdin_input = "\n".join(inputs_list) + "\n"
    
    try:
        env = os.environ.copy()
        env['PYTHONIOENCODING'] = 'utf-8'
        
        # é’ˆå¯¹ç‰¹å®šè„šæœ¬çš„ç¼–ç å¤„ç†ä¿æŒä¸å˜
        if "baidu_news_spider.py" in script_path:
             result = subprocess.run(
                [sys.executable, script_path],
                input=stdin_input.encode('utf-8'),
                capture_output=True,
                check=False,
                env=env,
                timeout=240
            )
             stdout = result.stdout.decode('utf-8', errors='replace')
             stderr = result.stderr.decode('utf-8', errors='replace')
             
        else:
            result = subprocess.run(
                [sys.executable, script_path],
                input=stdin_input,
                capture_output=True,
                text=True, 
                check=False,
                encoding='utf-8',
                env=env,
                timeout=240
            )
            stdout = result.stdout
            stderr = result.stderr


        if result.returncode != 0:
            return (f"âŒ è„šæœ¬è¿è¡Œå¤±è´¥ (Return Code: {result.returncode})!\n"
                    f"--- Standard Error ---\n"
                    f"{stderr}\n"
                    f"--- Standard Output (éƒ¨åˆ†) ---\n"
                    f"{stdout}")
        
        return f"âœ… è„šæœ¬è¿è¡ŒæˆåŠŸï¼\n" + stdout

    except subprocess.TimeoutExpired:
        return "âŒ è„šæœ¬è¿è¡Œè¶…æ—¶ (Timeout: 240s)ã€‚"
    except Exception as e:
        return f"âŒ è¿è¡Œè¿‡ç¨‹ä¸­å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}"


def get_spider_script_path(script_name: str) -> str:
    return os.path.join(CURRENT_DIR, "Spiders", "AllSpider", script_name)

# --- é€šç”¨çˆ¬è™«ä»»åŠ¡å‡½æ•° ---
def run_generic_spider_gr(script_name: str, keyword: str, sort_by_choice: str, max_pages: int) -> str:
    """
    é€šç”¨çˆ¬è™«è¿è¡Œå‡½æ•°ï¼Œæ ¹æ®è„šæœ¬åç§°è°ƒç”¨ run_external_script
    """
    script_path = get_spider_script_path(script_name)
    
    config = SPIDER_CONFIG.get(script_name, {})
    
    # 1. ç¡®å®šå…³é”®è¯ (ä½¿ç”¨è¾“å…¥å€¼ï¼Œè‹¥ä¸ºç©ºåˆ™ä½¿ç”¨é»˜è®¤å€¼)
    keyword_input = keyword if keyword else config.get('default_kw', 'é»˜è®¤å…³é”®è¯')
    
    # 2. ç¡®å®šè¾“å…¥åˆ—è¡¨ inputs
    inputs = [keyword_input]
    
    # 3. å¤„ç†æ’åº (ä»… baidu_news_spider.py ä½¿ç”¨)
    if config.get("sort"):
        # æ’åºå€¼æ˜ å°„: é»˜è®¤æ’åº -> '0', æ—¶é—´æ’åº -> '2', ç„¦ç‚¹æ’åº -> '1', åç§°æ’åº -> '3'
        # baidu_news_spider ä»…æ¥å— 1(ç„¦ç‚¹) æˆ– 2(æ—¶é—´)
        if script_name == "baidu_news_spider.py":
            sort_input = '1' if 'ç„¦ç‚¹' in sort_by_choice else '2' 
        else:
            sort_input = SORT_MAP.get(sort_by_choice, '0')
        inputs.append(sort_input)
        
    # 4. å¤„ç†é¡µæ•° (lenovo_app_spider.py å’Œ research_paper_spider.py ä½¿ç”¨)
    if config.get("pages"):
        # ç¡®ä¿ max_pages æ˜¯æ•´æ•°
        page_input = str(int(max_pages))
        inputs.append(page_input) # é¡µæ•°åœ¨å…³é”®è¯ä¹‹å
        
        # NOTE: é’ˆå¯¹æ‚¨çš„ç°æœ‰ä»£ç ç»“æ„ï¼Œbaidu_news_spider.py ä¸ä½¿ç”¨ max_pagesï¼Œå› æ­¤åªæœ‰ inputs=[keyword, sort]
        # lenovo_app_spider.py å’Œ research_paper_spider.py åº”è¯¥ä½¿ç”¨ inputs=[keyword, max_pages]
        # æ£€æŸ¥åŸå§‹å‡½æ•°é€»è¾‘ï¼š
        # run_spider_lenovo_app_gr(keyword, max_pages) -> inputs = [keyword, str(max_pages)]
        # run_spider_baidu_news_gr(keyword, sort) -> inputs = [keyword, sort_input]
        
        # ä¸ºäº†å…¼å®¹è¿™ä¸¤ç§æ¨¡å¼ï¼Œæˆ‘ä»¬ä¾èµ– config æ¥ç¡®å®š inputs çš„é¡ºåºå’Œæ•°é‡ã€‚
        # å¦‚æœæ˜¯ lenovo æˆ– researchï¼Œåªæœ‰ keyword å’Œ max_pages
        if script_name != "baidu_news_spider.py":
             inputs = [keyword_input, page_input]
            
    # 5. è¿è¡Œè„šæœ¬
    header = f"ğŸš€ æ­£åœ¨è¿è¡Œè„šæœ¬: **{script_name}** (è¾“å…¥: {inputs})\n"
    result = run_external_script(script_path, inputs)
    
    return header + result


# ====================================================================
# 2. æ¨¡å‹åŠ è½½å’Œé€šç”¨ä»»åŠ¡å‡½æ•° (æ›´æ–°ä¸ºå®é™…æ‰§è¡Œé€»è¾‘)
# ====================================================================

def init_model_and_tokenizer_gr(model_choice: str, state_tokenizer, state_model) -> tuple:
    """æ¨¡å‹åˆå§‹åŒ–å‡½æ•°ï¼ŒåŠ è½½æ¨¡å‹å¯¹è±¡åˆ° Gradio State"""
    is_mock_mode = torch is None # ä¾èµ–äºå…¨å±€çš„ torch å˜é‡ï¼ˆå¦‚æœå¯¼å…¥å¤±è´¥åˆ™ä¸º Noneï¼‰
    dependency_status = f"ğŸ”´ PyTorch/Transformers ä¾èµ–ç¼ºå¤± (Mockæ¨¡å¼)ã€‚" if is_mock_mode else "âœ… PyTorch/Transformers ä¾èµ–æ»¡è¶³ (çœŸå®æ¨ç†æ¨¡å¼)ã€‚"
    # --------------------------
    
    if is_mock_mode:
        status_msg = f"âŒ PyTorch åº“æœªå®‰è£…æˆ–åŠ è½½å¤±è´¥ã€‚æ— æ³•åŠ è½½çœŸå®æ¨¡å‹ã€‚\n{dependency_status}"
        return None, None, status_msg
        
    model_dir = os.path.join(MODEL_BASE_DIR, model_choice)
    
    if not os.path.exists(model_dir):
        status_msg = f"âŒ æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨ï¼š{model_dir}\nè¯·æ£€æŸ¥æ‚¨çš„æ–‡ä»¶ç»“æ„æ˜¯å¦ä¸ Program/Models/ ä¸€è‡´ã€‚\n{dependency_status}"
        return None, None, status_msg
        
    try:
        # ç»Ÿä¸€ä½¿ç”¨ CPU è¿›è¡Œæ¨¡å‹åŠ è½½ï¼Œé¿å… GPU æ˜¾å­˜ä¸è¶³é—®é¢˜
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        print(f"å°è¯•ä» {model_dir} åŠ è½½æ¨¡å‹...")
        
        # ä½¿ç”¨ quick_start.py ä¸­çš„é€»è¾‘ï¼ŒåŠ è½½ MegatronBertModel
        tokenizer = BertTokenizer.from_pretrained(model_dir)
        config = MegatronBertConfig.from_pretrained(model_dir)
        # æ³¨æ„ï¼šè¿™é‡Œç§»é™¤äº† dtype=torch.float16ï¼Œå› ä¸ºå®ƒå¯èƒ½å¯¼è‡´ CPU æˆ–éƒ¨åˆ† GPU ç¯å¢ƒå‡ºé”™
        model = MegatronBertModel.from_pretrained(model_dir, config=config, dtype=torch.float16)
        model.to(device)
        model.eval()
        
        state_tokenizer = tokenizer
        state_model = model

        status_msg = f"""
==================================================
âœ… æ¨¡å‹åˆå§‹åŒ–å®Œæˆ | ä½¿ç”¨è®¾å¤‡ï¼š{device.type.upper()}
ğŸ“Œ æ¨¡å‹ï¼š{model_choice}
{dependency_status}
==================================================
"""
        return state_tokenizer, state_model, status_msg

    except Exception as e:
        status_msg = f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥ï¼š{e}\nè¯·ç¡®ä¿æ¨¡å‹æƒé‡å®Œæ•´ä¸”å·²å®‰è£…æ‰€æœ‰ä¾èµ–ï¼ˆå¦‚ `protobuf`ï¼‰ã€‚\nTrace: {traceback.format_exc()}\n{dependency_status}"
        return None, None, status_msg

# --- Helper for CSL Similarity Verification (for batch) ---
def perform_csl_inference(model, tokenizer, device, abstract: str, keywords_input: str):
    """
    æ‰§è¡Œå•æ¡ CSL ä»»åŠ¡ï¼ˆæ‘˜è¦å…³é”®è¯éªŒè¯ï¼‰çš„ç›¸ä¼¼åº¦è®¡ç®—å’Œåˆ¤æ–­
    """
    if not abstract or not keywords_input:
        return 0.0, "âš ï¸ æ–‡æœ¬æˆ–å…³é”®è¯ä¸ºç©º"
        
    keywords = [k.strip() for k in re.split(r"[,ï¼Œ]", keywords_input) if k.strip()]
    keywords_text = "ï¼Œ".join(keywords)

    # 1. ç¼–ç æ‘˜è¦å’Œå…³é”®è¯
    abstract_encoded = tokenizer(abstract, return_tensors="pt", padding=True, truncation=True, max_length=256).to(device)
    keywords_encoded = tokenizer(keywords_text, return_tensors="pt", padding=True, truncation=True, max_length=64).to(device)
    
    # 2. æå–ç‰¹å¾
    with torch.no_grad():
        abstract_output = model(**abstract_encoded)
        abstract_feat = abstract_output.pooler_output
        keywords_output = model(**keywords_encoded)
        keywords_feat = keywords_output.pooler_output
    
    # 3. è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦ï¼ˆå½’ä¸€åŒ–åï¼‰
    abstract_feat_norm = F.normalize(abstract_feat, p=2, dim=1)
    keywords_feat_norm = F.normalize(keywords_feat, p=2, dim=1)
    similarity = torch.mm(abstract_feat_norm, keywords_feat_norm.T).item()
    
    # 4. äºŒåˆ†ç±»åˆ¤æ–­
    threshold = 0.3 # quick_start.py é»˜è®¤é˜ˆå€¼
    is_accurate = "âœ… å‡†ç¡®" if similarity >= threshold else "âŒ ä¸å‡†ç¡®"
    
    return similarity, is_accurate

# --- Helper for Classification Tasks (TNEWS, CSLDCP, IFLYTEK) (for batch) ---
def perform_classification_inference(model, tokenizer, device, text: str, label_map: dict):
    """
    æ‰§è¡Œå•æ¡åˆ†ç±»ä»»åŠ¡ï¼ˆTNEWS, CSLDCP, IFLYTEKï¼‰çš„é›¶æ ·æœ¬åˆ†ç±»
    """
    if not text:
        return "N/A", 0.0, None # é¢„æµ‹æ ‡ç­¾, ç½®ä¿¡åº¦, æ‰€æœ‰ç›¸ä¼¼åº¦
        
    encoded = tokenizer(text, return_tensors="pt", padding=True, truncation=True, max_length=512).to(device)
    with torch.no_grad():
        outputs = model(**encoded)
        text_feat = outputs.pooler_output
    
    pred_idx, _, confidence, all_similarities = predict_by_similarity(model, tokenizer, device, text_feat, label_map)
    pred_label = label_map.get(pred_idx, f"æœªçŸ¥ç±»åˆ« ({pred_idx})")
    
    return pred_label, confidence, all_similarities # è¿”å›æ‰€æœ‰ç›¸ä¼¼åº¦ï¼Œç”¨äºCHIDF

# --- é€šç”¨æ¨¡å‹æ¨ç†å‡½æ•° ---
def run_model_task_gr(task_name: str, tokenizer, model, *args) -> str:
    """
    é€šç”¨æ¨¡å‹ä»»åŠ¡è¿è¡Œå™¨ï¼šæ‰§è¡Œ quick_start.py ä¸­çš„å…¨éƒ¨é›¶æ ·æœ¬/ç‰¹å¾åŒ¹é…é€»è¾‘ã€‚
    """
    if not model or not tokenizer:
        return "âŒ æ¨¡å‹æœªåŠ è½½ï¼Œè¯·å…ˆåœ¨ã€æ¨¡å‹é€‰æ‹©ã€‘åŒºåŸŸåŠ è½½æ¨¡å‹ï¼"
        
    output = f"ğŸ“ ä»»åŠ¡ï¼š{task_name} - æ¨¡å‹: {model.__class__.__name__}\n"
    
    is_mock_mode = "MockModel" in model.__class__.__name__
    if is_mock_mode:
        output += "âš ï¸ **å½“å‰è¾“å‡ºä¸ºæ¨¡æ‹Ÿ (Mock) ç»“æœï¼Œè¯·å®‰è£… PyTorch/Transformers ä¾èµ–!**\n"
    else:
        output += "âœ… **å½“å‰è¾“å‡ºä¸ºæ¨¡å‹çœŸå® (Real) æ¨ç†ç»“æœã€‚**\n"
    
    output += "==================================================\n"
    device = model.device 

    try:
        # --- ä»»åŠ¡ 1: CHIDF (æˆè¯­å¡«ç©º) ---
        if task_name == "æˆè¯­å¡«ç©ºï¼ˆCHIDFï¼‰":
            user_text, candidate_input = args
            
            if "[MASK]" not in user_text:
                return "âŒ è¾“å…¥é”™è¯¯ï¼šè¯·åœ¨å¥å­ä¸­æ·»åŠ [MASK]æ ‡è®°æˆè¯­ç©ºç¼ºä½ç½®ï¼"
            
            # 1. ç¼–ç æ–‡æœ¬å¹¶æå–[MASK]ä½ç½®ç‰¹å¾
            encoded = tokenizer(user_text, return_tensors="pt", padding=True, truncation=True, max_length=64).to(device)
            mask_pos = torch.where(encoded["input_ids"] == tokenizer.mask_token_id)[1]
            if len(mask_pos) == 0:
                return "âŒ æœªè¯†åˆ«åˆ°[MASK]æ ‡è®°ï¼Œè¯·é‡æ–°è¾“å…¥ï¼"
                
            with torch.no_grad():
                outputs = model(**encoded)
                mask_feat = outputs.last_hidden_state[0, mask_pos, :]
            
            # 2. å‡†å¤‡å€™é€‰æˆè¯­
            candidate_idioms = [idiom.strip() for idiom in candidate_input.split("ï¼Œ") if idiom.strip()]
            if not candidate_idioms:
                 candidate_idioms = ["åšæŒä¸æ‡ˆ", "åŠé€”è€ŒåºŸ", "ç•ç¼©ä¸å‰", "æ•·è¡äº†äº‹"]
                 output += f"âš ï¸ æœªè¾“å…¥å€™é€‰æˆè¯­ï¼Œä½¿ç”¨é»˜è®¤å€™é€‰ï¼š{','.join(candidate_idioms)}\n"
            
            # 3. æå–å€™é€‰ç‰¹å¾
            candidate_feats = []
            for idiom in candidate_idioms:
                template_text = f"è¿™ä¸ªæˆè¯­çš„æ„æ€æ˜¯ï¼š{idiom}"
                idiom_encoded = tokenizer(template_text, return_tensors="pt", padding=True, truncation=True, max_length=32).to(device)
                with torch.no_grad():
                    idiom_output = model(** idiom_encoded)
                    idiom_feat = idiom_output.pooler_output 
                    candidate_feats.append(idiom_feat)
            
            candidate_feats = torch.cat(candidate_feats, dim=0)
            
            # 4. è®¡ç®—ç›¸ä¼¼åº¦ï¼ˆå½’ä¸€åŒ–åï¼‰
            mask_feat_norm = F.normalize(mask_feat, p=2, dim=1)
            candidate_feats_norm = F.normalize(candidate_feats, p=2, dim=1)
            similarities = torch.mm(mask_feat_norm, candidate_feats_norm.T)[0]
            
            best_idx = torch.argmax(similarities).item()
            
            # 5. ä¿®æ­£ï¼šå±•ç¤ºæ‰€æœ‰æˆè¯­çš„åŒ¹é…åº¦
            output += f"ğŸ“– åŸå¥ï¼š{user_text}\n"
            output += "--------------------------------------------------\n"
            output += "| å€™é€‰æˆè¯­ | åŸå§‹ç›¸ä¼¼åº¦ | å½’ä¸€åŒ–ç½®ä¿¡åº¦ | æœ€ä½³åŒ¹é… |\n"
            output += "| :---: | :---: | :---: | :---: |\n"
            
            result_lines = []
            for i, idiom in enumerate(candidate_idioms):
                raw_similarity = similarities[i].item()
                # å°† [-1, 1] ç›¸ä¼¼åº¦æ˜ å°„åˆ° [0, 1] æ˜¾ç¤º
                # normalized_confidence = (raw_similarity + 1) / 2 # å½’ä¸€åŒ–å¯èƒ½è¯¯å¯¼ï¼Œç›´æ¥æ˜¾ç¤ºç›¸ä¼¼åº¦å³å¯
                normalized_confidence = raw_similarity
                
                is_best = "ğŸ† YES" if i == best_idx else "NO"
                
                result_lines.append(
                    f"| {idiom} | {raw_similarity:.4f} | {normalized_confidence:.4f} | {is_best} |"
                )
            
            output += "\n".join(result_lines)
            return output

        # --- ä»»åŠ¡ 2: TNEWS (æ–°é—»åˆ†ç±») ---
        elif task_name == "æ–°é—»åˆ†ç±»ï¼ˆTNEWSï¼‰":
            news_text = args[0]
            
            pred_label, confidence, all_similarities = perform_classification_inference(model, tokenizer, device, news_text, TNEWS_LABELS)
            
            output += f"ğŸ“„ æ–°é—»æ–‡æœ¬ï¼š{news_text[:50]}...\n"
            output += f"ğŸ† é¢„æµ‹ç±»åˆ«ï¼š**{pred_label}** (ç½®ä¿¡åº¦: {confidence:.4f})\n"
            
            # å±•ç¤ºæ‰€æœ‰åˆ†ç±»ç»“æœ
            output += "--------------------------------------------------\n"
            output += "| ç±»åˆ« | ç½®ä¿¡åº¦ |\n"
            output += "| :---: | :---: |\n"
            
            # ç»“åˆæ ‡ç­¾åç§°å’Œæ¦‚ç‡è¿›è¡Œæ’åºå±•ç¤º
            all_results = []
            for idx, label in TNEWS_LABELS.items():
                all_results.append((label, all_similarities[idx]))
            
            # ä½¿ç”¨ç›¸ä¼¼åº¦æ’åº
            all_results.sort(key=lambda x: x[1], reverse=True)
            
            for label, similarity in all_results:
                 output += f"| {label} | {similarity:.4f} |\n"
            
            return output

        # --- ä»»åŠ¡ 3: OCNLI (è‡ªç„¶è¯­è¨€æ¨ç†) ---
        elif task_name == "è‡ªç„¶è¯­è¨€æ¨ç†ï¼ˆOCNLIï¼‰":
            sent1, sent2 = args
            
            # ç¼–ç å¥å­å¯¹
            nli_text = f"{sent1} {tokenizer.sep_token} {sent2}"
            
            pred_label, confidence, _ = perform_classification_inference(model, tokenizer, device, nli_text, OCNLI_LABELS)
            
            output += f"å¥å­1 (å‰æ): {sent1}\n"
            output += f"å¥å­2 (å‡è®¾): {sent2}\n"
            output += f"ğŸ† æ¨ç†ç»“æœï¼š**{pred_label}** (ç½®ä¿¡åº¦: {confidence:.4f})"
            
            return output

        # --- ä»»åŠ¡ 4: CSL (æ‘˜è¦å…³é”®è¯éªŒè¯) ---
        elif task_name == "æ‘˜è¦å…³é”®è¯éªŒè¯ï¼ˆCSLï¼‰":
            abstract, keywords_input = args
            
            similarity, is_accurate = perform_csl_inference(model, tokenizer, device, abstract, keywords_input)
            
            output += f"æ‘˜è¦: {abstract[:50]}...\n"
            output += f"å…³é”®è¯: {keywords_input}\n"
            output += f"è¯­ä¹‰ç›¸ä¼¼åº¦: **{similarity:.4f}** (é˜ˆå€¼ 0.3)\n"
            output += f"ğŸ† éªŒè¯ç»“æœï¼ˆç›¸ä¼¼åº¦ï¼‰ï¼š**{is_accurate}**"

            return output

        # --- ä»»åŠ¡ 5: CSLDCP (ä¸»é¢˜æ–‡çŒ®åˆ†ç±») ---
        elif task_name == "ä¸»é¢˜æ–‡çŒ®åˆ†ç±»ï¼ˆCSLDCPï¼‰":
            abstract = args[0]
            
            pred_label, confidence, _ = perform_classification_inference(model, tokenizer, device, abstract, CSLDCP_LABELS)
            
            output += f"æ‘˜è¦: {abstract[:50]}...\n"
            output += f"ğŸ† é¢„æµ‹ä¸»é¢˜ï¼š**{pred_label}** (ç½®ä¿¡åº¦: {confidence:.4f})"
            
            return output

        # --- ä»»åŠ¡ 6: IFLYTEK (åº”ç”¨æè¿°åˆ†ç±») ---
        elif task_name == "åº”ç”¨æè¿°åˆ†ç±»ï¼ˆIFLYTEKï¼‰":
            description = args[0]
            
            pred_label, confidence, _ = perform_classification_inference(model, tokenizer, device, description, IFLYTEK_LABELS)
            
            output += f"æè¿°: {description[:50]}...\n"
            output += f"ğŸ† é¢„æµ‹ç±»åˆ«ï¼š**{pred_label}** (ç½®ä¿¡åº¦: {confidence:.4f})"
            
            return output

        # --- ä»»åŠ¡ 7: CLUEWSC (æŒ‡ä»£æ¶ˆè§£) ---
        elif task_name == "æŒ‡ä»£æ¶ˆè§£ï¼ˆCLUEWSCï¼‰":
            user_text, target_word, _ = args # å¿½ç•¥ target_pos
            
            # ç®€åŒ–çš„é›¶æ ·æœ¬æç¤º
            wsc_labels = {0: "å…±æŒ‡", 1: "ä¸å…±æŒ‡"}
            
            # ä½¿ç”¨å¥å­æœ¬èº«ä½œä¸ºè¾“å…¥ï¼Œè®©æ¨¡å‹åˆ¤æ–­å¥å­ç»“æ„çš„åˆç†æ€§
            pred_label, confidence, _ = perform_classification_inference(model, tokenizer, device, user_text, wsc_labels)
            
            output += f"å¥å­: {user_text}\n"
            output += f"æŒ‡ä»£è¯: {target_word}\n"
            output += f"ğŸ† æ¶ˆè§£ç»“æœï¼š**{pred_label}** (ç½®ä¿¡åº¦: {confidence:.4f})\n"
            # output += "ï¼ˆæ³¨æ„ï¼šè¯¥ä»»åŠ¡é€šå¸¸éœ€è¦ä¸“é—¨çš„Span-Predictionå¤´ï¼Œæ­¤ä¸ºç®€åŒ–é›¶æ ·æœ¬æ¼”ç¤ºï¼‰"
            
            return output

    except Exception as e:
        return f"âŒ å®é™…æ¨ç†å¤±è´¥ï¼š{type(e).__name__}: {e}\nè¯·æ£€æŸ¥æ¨¡å‹æƒé‡æ˜¯å¦åŒ¹é… MegatronBertModelï¼Œæˆ–ä»»åŠ¡è¾“å…¥æ˜¯å¦æ­£ç¡®ã€‚\nTrace: {traceback.format_exc()}"

# --- ä»»åŠ¡è·¯å¾„å’Œæ–‡ä»¶æ‰«æå‡½æ•°ï¼ˆä¿æŒä¸å˜ï¼‰---
def get_data_folder_path(task_name: str) -> str:
    mapping = {
        "æ–°é—»åˆ†ç±»ï¼ˆTNEWSï¼‰": os.path.join(DATA_BASE_DIR, "News"),
        "æ‘˜è¦å…³é”®è¯éªŒè¯ï¼ˆCSLï¼‰": os.path.join(DATA_BASE_DIR, "Literature"),
        "ä¸»é¢˜æ–‡çŒ®åˆ†ç±»ï¼ˆCSLDCPï¼‰": os.path.join(DATA_BASE_DIR, "Literature"),
        "åº”ç”¨æè¿°åˆ†ç±»ï¼ˆIFLYTEKï¼‰": os.path.join(DATA_BASE_DIR, "AppDescriptions")
    }
    return mapping.get(task_name, "è·¯å¾„æœªçŸ¥")

def list_task_csv_files(task_name: str) -> list:
    folder_path = get_data_folder_path(task_name)
    if "æœªçŸ¥" in folder_path or not os.path.isdir(folder_path):
        return [f"âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ°ä»»åŠ¡ '{task_name}' çš„æ•°æ®è·¯å¾„é…ç½®æˆ–æ–‡ä»¶å¤¹ä¸å­˜åœ¨ã€‚"]
    try:
        csv_files = [os.path.basename(f) for f in glob.glob(os.path.join(folder_path, '*.csv'))]
        return csv_files if csv_files else [f"âš ï¸ è­¦å‘Šï¼šæ–‡ä»¶å¤¹å†…æ²¡æœ‰æ‰¾åˆ° .csv æ–‡ä»¶: {os.path.basename(folder_path)}/"]
    except Exception as e:
        return [f"âŒ æ‰«ææ–‡ä»¶æ—¶å‡ºé”™: {e}"]

def get_initial_file_choice(task_name: str):
    file_list = list_task_csv_files(task_name)
    if file_list and not file_list[0].startswith(("âŒ", "âš ï¸")):
        return file_list[0]
    return None

# --- ä¿®æ­£åçš„è¯»å–å’Œé¢„è§ˆå‡½æ•°ï¼ŒåŒ…å«åˆ—åæ£€æŸ¥ ---
def read_and_preview_data(task_name: str, file_name: str) -> str:
    if file_name.startswith(("âŒ", "âš ï¸")): return file_name
    folder_path = get_data_folder_path(task_name)
    file_path = os.path.join(folder_path, file_name)
    
    if "æœªçŸ¥" in folder_path or not os.path.exists(file_path):
        return (f"âš ï¸ é¢„æœŸæ•°æ®æ–‡ä»¶ä¸å­˜åœ¨ã€‚\n"
                f"è¯·ç¡®ä¿æ‚¨çš„æµ‹è¯•æ•°æ®ä½äº: **{file_path}**")

    try:
        preview_lines = []
        required_cols = TASK_COLUMN_MAP.get(task_name, {})
        
        if file_path.endswith('.csv'):
            with open(file_path, 'r', encoding='utf-8') as f:
                reader = csv.reader(f)
                header = next(reader, None)
                
                if header and header[0].startswith('\ufeff'):
                    header[0] = header[0].lstrip('\ufeff')

                # æ£€æŸ¥åˆ—å
                if header and required_cols:
                    indices, missing = find_column_indices(header, required_cols)
                    if missing:
                        preview_lines.append(f"âŒ è­¦å‘Šï¼šCSVæ–‡ä»¶ä¸­ç¼ºå°‘å¿…éœ€çš„åˆ—ï¼š{', '.join(missing)}")
                        preview_lines.append(f"âš ï¸ å¿…éœ€åˆ—: è¾“å…¥='{required_cols.get('input', 'N/A')}'")
                
                if header:
                    preview_lines.append("Header: " + ", ".join(header))
                
                # è¯»å–å‰10è¡Œæ•°æ®
                count = 0
                for i, row in enumerate(reader):
                    # é™åˆ¶é¢„è§ˆé•¿åº¦ï¼Œé¿å…å¤ªé•¿
                    row_preview = [item[:50] + '...' if len(item) > 50 else item for item in row]
                    preview_lines.append(f"Row {i+1}: {row_preview}")
                    count += 1
                    if count >= 10:
                        preview_lines.append("...")
                        break
        
        preview_output = "\n".join(preview_lines)

        return (f"âœ… æ•°æ®æ–‡ä»¶æ‰¾åˆ°: {os.path.basename(file_path)}\n"
                f"ğŸ“Œ å®Œæ•´è·¯å¾„: {file_path}\n"
                f"--- æ–‡ä»¶å†…å®¹é¢„è§ˆ (å‰ {count} è¡Œ) ---\n"
                f"{preview_output}")

    except Exception as e:
        return f"âŒ è¯»å–æ•°æ®æ–‡ä»¶æ—¶å‡ºé”™: {e}\nè¯·æ£€æŸ¥æ–‡ä»¶ç¼–ç æˆ–æ ¼å¼æ˜¯å¦æ­£ç¡®ã€‚\nTrace: {traceback.format_exc()}"


def run_model_batch_task_gr(task_name: str, tokenizer, model, file_name: str):
    """
    æ‰¹é‡æ¨ç†ä»»åŠ¡ï¼šå®é™…æ‰§è¡Œæ–‡ä»¶I/Oï¼Œå¾ªç¯è°ƒç”¨æ¨¡å‹æ¨ç†é€»è¾‘ï¼Œå¹¶å°†æ‰€æœ‰ç»“æœæ ¼å¼åŒ–åè¾“å‡ºåˆ° Gradio ç»“æœæ¡†ã€‚
    ä¿®æ­£ï¼šä½¿ç”¨åˆ—ååŠ¨æ€è¯»å– CSV æ•°æ®ã€‚
    """
    if not model or not tokenizer:
        return "âŒ æ¨¡å‹æœªåŠ è½½ï¼Œè¯·å…ˆåœ¨ã€æ¨¡å‹é€‰æ‹©ã€‘åŒºåŸŸåŠ è½½æ¨¡å‹ï¼"
    
    if file_name.startswith(("âŒ", "âš ï¸")):
        return file_name

    folder_path = get_data_folder_path(task_name)
    file_path = os.path.join(folder_path, file_name)
    
    if "æœªçŸ¥" in folder_path or not os.path.exists(file_path):
         return read_and_preview_data(task_name, file_name)
        
    device = model.device 
    total_processed = 0
    results_rows = []
    
    start_time = time.time()
    
    # 1. ç¡®å®šä»»åŠ¡é…ç½®å’Œè¾“å‡ºHeader
    required_cols = TASK_COLUMN_MAP.get(task_name)
    
    # === å…³é”®ä¿®å¤ç‚¹ A: æ ¹æ®ä»»åŠ¡ç¡®å®šå¿…éœ€çš„è¾“å…¥åˆ—é›†åˆ ===
    # å¯¹äºæ‰€æœ‰ä»»åŠ¡ï¼Œ'input' åˆ—æ˜¯å¿…éœ€çš„
    required_input_keys = {'input'} 
    # CSL ä»»åŠ¡è¿˜éœ€è¦ 'true_value' åˆ—ï¼ˆå…³é”®è¯ï¼‰
    if task_name == "æ‘˜è¦å…³é”®è¯éªŒè¯ï¼ˆCSLï¼‰":
        required_input_keys.add('true_value')
        output_header = ['Input_Text (æ‘˜è¦)', 'True_Keywords', 'Predicted_Result', 'Similarity']
        
    else:
        # TNEWS, CSLDCP, IFLYTEK (Classification)
        # è¿™äº›ä»»åŠ¡çš„è¾“å…¥åªéœ€è¦ 'input'
        output_header = ['Input_Text', 'Predicted_Label', 'Confidence']
        label_map = {
            "æ–°é—»åˆ†ç±»ï¼ˆTNEWSï¼‰": TNEWS_LABELS,
            "ä¸»é¢˜æ–‡çŒ®åˆ†ç±»ï¼ˆCSLDCPï¼‰": CSLDCP_LABELS,
            "åº”ç”¨æè¿°åˆ†ç±»ï¼ˆIFLYTEKï¼‰": IFLYTEK_LABELS,
        }[task_name]
    
    # 2. è¯»å– CSV æ–‡ä»¶ (ä½¿ç”¨ utf-8 ç¡®ä¿å…¼å®¹æ€§)
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            reader = csv.reader(f)
            
            # Read and process header
            header = next(reader, None)
            if not header:
                return "âŒ æ‰¹é‡æ¨ç†å¤±è´¥: æ–‡ä»¶å†…å®¹ä¸ºç©ºæˆ–ç¼ºå°‘ Headerã€‚"
            
            # === ä¿®å¤ï¼šæ£€æŸ¥å¹¶ç§»é™¤ç¬¬ä¸€ä¸ªåˆ—åä¸Šçš„ BOM å­—ç¬¦ (\ufeff) ===
            if header and header[0].startswith('\ufeff'):
                header[0] = header[0].lstrip('\ufeff')
            # Find column indices (åªä¼ å…¥å¿…éœ€çš„åˆ—å)
            # === å…³é”®ä¿®å¤ç‚¹ B: åŠ¨æ€æ„é€ å¿…éœ€åˆ—å­—å…¸ ===
            cols_to_check = {k: required_cols[k] for k in required_input_keys if k in required_cols}
            indices, missing = find_column_indices(header, cols_to_check)
            
            if missing:
                return (f"âŒ æ‰¹é‡æ¨ç†å¤±è´¥: CSV æ–‡ä»¶ä¸­ç¼ºå°‘å¿…éœ€çš„åˆ—ï¼š{', '.join(missing)}\n"
                        f"å¿…éœ€åˆ—: {', '.join([f'{k}={v}' for k, v in cols_to_check.items()])}")
                
            input_idx = indices['input']
            
            # === å…³é”®ä¿®å¤ç‚¹ C: çµæ´»å¤„ç† true_value_idx/True_Label ===
            # CSL ä»»åŠ¡ï¼štrue_value_idx æ˜¯å¿…éœ€çš„
            if task_name == "æ‘˜è¦å…³é”®è¯éªŒè¯ï¼ˆCSLï¼‰":
                true_value_idx = indices['true_value']
            # åˆ†ç±»ä»»åŠ¡ï¼šå°è¯•æŸ¥æ‰¾ True Label åˆ—ï¼ˆå¦‚'label'ã€'true_label'ï¼‰ï¼Œæ‰¾ä¸åˆ°åˆ™è®¾ä¸º -1 (N/A)
            else:
                header_map = {col.strip(): idx for idx, col in enumerate(header)}
                true_value_idx = header_map.get('çœŸå®æ ‡ç­¾', -1) # å‡è®¾çœŸå®æ ‡ç­¾åˆ—åå¯èƒ½æ˜¯ 'çœŸå®æ ‡ç­¾'
                if true_value_idx == -1:
                    true_value_idx = header_map.get('True_Label', -1) # å°è¯•è‹±æ–‡
                    if true_value_idx == -1:
                        # å¯¹äºåˆ†ç±»ä»»åŠ¡ï¼Œå¦‚æœæ‰¾ä¸åˆ°çœŸå®æ ‡ç­¾åˆ—ï¼Œæˆ‘ä»¬å…è®¸ç»§ç»­ï¼Œåªæ˜¯ True_Label å­—æ®µä¼šæ˜¾ç¤º N/A
                        print(f"")


            # 3. å¾ªç¯æ¨ç†
            for row in reader:
                # ç¡®ä¿è¡Œæœ‰è¶³å¤Ÿçš„åˆ—æ¥è¯»å–è¾“å…¥æ–‡æœ¬å’Œï¼ˆå¦‚æœå­˜åœ¨ï¼‰çœŸå®å€¼/å…³é”®è¯
                if not row or len(row) <= input_idx: continue 
                
                try:
                    
                    input_text = row[input_idx].strip() # ä½¿ç”¨æ‰¾åˆ°çš„ç´¢å¼•è¯»å–è¾“å…¥æ–‡æœ¬
                    
                    # è·å–çœŸå®å€¼ï¼šå¦‚æœç´¢å¼•æœ‰æ•ˆåˆ™è¯»å–ï¼Œå¦åˆ™è®¾ä¸º N/A
                    if true_value_idx != -1 and len(row) > true_value_idx:
                         true_value = row[true_value_idx].strip()
                    else:
                         true_value = "N/A"
                         
                    if not input_text: continue # è·³è¿‡ç©ºè¾“å…¥æ–‡æœ¬
                    
                    total_processed += 1
                    
                    if task_name == "æ‘˜è¦å…³é”®è¯éªŒè¯ï¼ˆCSLï¼‰":
                        # CSLéœ€è¦ (Abstract, Keywords)
                        # ç¡®ä¿ true_value æ˜¯å…³é”®è¯
                        similarity, pred_result = perform_csl_inference(model, tokenizer, device, input_text, true_value)
                        
                        results_rows.append([
                            input_text[:50] + '...' if len(input_text) > 50 else input_text,
                            true_value,
                            pred_result, 
                            f"{similarity:.4f}"
                        ])

                    else:
                        pred_label, confidence, _ = perform_classification_inference(model, tokenizer, device, input_text, label_map)
                        
                        results_rows.append([
                            input_text[:50] + '...' if len(input_text) > 50 else input_text,
                            pred_label, 
                            f"{confidence:.4f}"
                        ])
                
                except IndexError:
                    print(f"âš ï¸ è­¦å‘Š: ç¬¬ {total_processed} è¡Œæ•°æ®åˆ—æ•°ä¸è¶³æˆ–ç´¢å¼•é”™è¯¯ï¼Œè·³è¿‡å¤„ç†ã€‚")
                    total_processed -= 1 
                    continue

    except Exception as e:
        return (f"âŒ æ‰¹é‡æ¨ç†è¯»å–æ–‡ä»¶å¤±è´¥ï¼š{type(e).__name__}: {e}\n"
                f"è¯·æ£€æŸ¥ CSV æ–‡ä»¶è·¯å¾„ã€æ ¼å¼å’Œå†…å®¹æ˜¯å¦æ­£ç¡®ã€‚\n"
                f"--- Traceback ---\n{traceback.format_exc()}")
                
    end_time = time.time()
    
    # 4. æ ¼å¼åŒ–è¾“å‡ºä¸º Markdown è¡¨æ ¼
    output = f"ğŸ“ ä»»åŠ¡ï¼š{task_name} - æ‰¹é‡æ¨ç† \n"

    is_mock_mode = "MockModel" in model.__class__.__name__
    if is_mock_mode:
        output += "âš ï¸ **å½“å‰è¾“å‡ºä¸ºæ¨¡æ‹Ÿ (Mock) ç»“æœï¼Œè¯·å®‰è£… PyTorch/Transformers ä¾èµ–!**\n"
    else:
        output += "âœ… **å½“å‰è¾“å‡ºä¸ºæ¨¡å‹çœŸå® (Real) æ¨ç†ç»“æœã€‚**\n"

    output += "==================================================\n"
    output += f"ğŸ“‚ æ•°æ®æ–‡ä»¶: {file_name}\n" 
    output += f"ğŸ“Š æ€»å…±å¤„ç†äº† **{total_processed}** æ¡æ•°æ®ã€‚\n"
    output += f"â±ï¸ æ€»è€—æ—¶: **{end_time - start_time:.2f} ç§’**\n"
    # output += "âš ï¸ **æ³¨æ„ï¼š** æ¨¡å‹æ¨ç†é€Ÿåº¦å–å†³äºæ‚¨çš„ç¡¬ä»¶æ€§èƒ½ï¼ˆå°¤å…¶æ˜¯ GPUï¼‰ã€‚**æ‰¹é‡å¤„ç†è€—æ—¶è¾ƒé•¿æ˜¯æ­£å¸¸ç°è±¡ã€‚**\n\n"
    
    # æ„é€  Markdown è¡¨æ ¼
    output += "| " + " | ".join(output_header) + " |\n"
    # æ„é€ å¯¹é½çº¿
    output += "| :---: | " + " | ".join([':---:'] * (len(output_header) - 1)) + " |\n"
    
    for row in results_rows:
        output += "| " + " | ".join([str(item) for item in row]) + " |\n"
        
    return output

# --- ä»»åŠ¡å‡½æ•°åŒ…è£…å™¨ (ä¿æŒä¸å˜) ---
def chidf_task_gr(tokenizer, model, user_text: str, candidate_input: str):
    return run_model_task_gr("æˆè¯­å¡«ç©ºï¼ˆCHIDFï¼‰", tokenizer, model, user_text, candidate_input)
def tnews_task_gr(tokenizer, model, news_text: str):
    return run_model_task_gr("æ–°é—»åˆ†ç±»ï¼ˆTNEWSï¼‰", tokenizer, model, news_text)
def tnews_batch_gr(tokenizer, model, file_name: str):
    return run_model_batch_task_gr("æ–°é—»åˆ†ç±»ï¼ˆTNEWSï¼‰", tokenizer, model, file_name)
def ocnli_task_gr(tokenizer, model, sent1: str, sent2: str):
    return run_model_task_gr("è‡ªç„¶è¯­è¨€æ¨ç†ï¼ˆOCNLIï¼‰", tokenizer, model, sent1, sent2)
def csl_task_gr(tokenizer, model, abstract: str, keywords_input: str):
    return run_model_task_gr("æ‘˜è¦å…³é”®è¯éªŒè¯ï¼ˆCSLï¼‰", tokenizer, model, abstract, keywords_input)
def csl_batch_gr(tokenizer, model, file_name: str):
    return run_model_batch_task_gr("æ‘˜è¦å…³é”®è¯éªŒè¯ï¼ˆCSLï¼‰", tokenizer, model, file_name)
def csldcp_task_gr(tokenizer, model, abstract: str):
    return run_model_task_gr("ä¸»é¢˜æ–‡çŒ®åˆ†ç±»ï¼ˆCSLDCPï¼‰", tokenizer, model, abstract)
def csldcp_batch_gr(tokenizer, model, file_name: str):
    return run_model_batch_task_gr("ä¸»é¢˜æ–‡çŒ®åˆ†ç±»ï¼ˆCSLDCPï¼‰", tokenizer, model, file_name)
def iflytek_task_gr(tokenizer, model, description: str):
    return run_model_task_gr("åº”ç”¨æè¿°åˆ†ç±»ï¼ˆIFLYTEKï¼‰", tokenizer, model, description)
def iflytek_batch_gr(tokenizer, model, file_name: str):
    return run_model_batch_task_gr("åº”ç”¨æè¿°åˆ†ç±»ï¼ˆIFLYTEKï¼‰", tokenizer, model, file_name)
def cluewsc_task_gr(tokenizer, model, user_text: str, target_word: str, target_pos: int):
    # CLUEWSC ä»»åŠ¡ä¸éœ€è¦ target_pos å­—æ®µï¼Œä½†ä¿ç•™è¾“å…¥ä»¥åŒ¹é… UI
    return run_model_task_gr("æŒ‡ä»£æ¶ˆè§£ï¼ˆCLUEWSCï¼‰", tokenizer, model, user_text, target_word, target_pos)


# ====================================================================
# 3. Gradio ç•Œé¢æ„å»º
# ====================================================================

with gr.Blocks(title="ä¼ªÂ·åŸç¥å¯åŠ¨å™¨") as demo:
    gr.Markdown("# ä¿¡æ¯èšåˆåŠŸèƒ½åŠæ¨¡å‹è°ƒè¯•WebUIï¼ˆåŸäºŒéƒç¥å¯åŠ¨å™¨<ç®€ç§°åŸç¥å¯åŠ¨å™¨>ï¼‰")
    
    state_tokenizer = gr.State(None)
    state_model = gr.State(None)
    
    with gr.Tabs():
        
        # --- çˆ¬è™«éƒ¨åˆ† (æ–‡æœ¬æ¡†è¡Œæ•°å¢åŠ ) ---
        with gr.TabItem("1. ç½‘é¡µçˆ¬å–"):
            gr.Markdown(f"## ğŸŒ çˆ¬å–è®¾å®š (è·¯å¾„: Program/Spiders/AllSpider/)\n") # è„šæœ¬è·¯å¾„: Program/Spiders/AllSpider/
            
            # åŠ¨æ€é€‰æ‹©çˆ¬è™«è„šæœ¬
            spider_choice = gr.Dropdown(
                label="é€‰æ‹©çˆ¬è™«è„šæœ¬",
                choices=SPIDER_FILES, # ä½¿ç”¨æ‰«æåˆ°çš„æ–‡ä»¶åˆ—è¡¨
                value=SPIDER_FILES[0] if SPIDER_FILES else "æœªæ‰¾åˆ°è„šæœ¬",
                interactive=bool(SPIDER_FILES)
            )

            # é€šç”¨è¾“å…¥æ§ä»¶
            spider_kw = gr.Textbox(label="æœç´¢å…³é”®è¯", value="äººå·¥æ™ºèƒ½")
            
            # æ’åºæ–¹å¼ (å‡è®¾æœ€å¤šæ”¯æŒ 4 ç§æ’åº)
            # æ³¨æ„ï¼šæ­¤å¤„ä½¿ç”¨ Dropdown ä»¥å…¼å®¹æ‰€æœ‰è„šæœ¬ï¼Œå¹¶é€šè¿‡åç«¯é€»è¾‘åˆ¤æ–­æ˜¯å¦ä½¿ç”¨
            spider_sort = gr.Radio(
                label="æ’åºæ–¹å¼",
                choices=SORT_CHOICES, 
                value="é»˜è®¤æ’åº",
                # é»˜è®¤å¯è§ï¼Œä½†å¯ä»¥æ ¹æ®é€‰æ‹©çš„è„šæœ¬åŠ¨æ€éšè—/ç¦ç”¨ (é«˜çº§åŠŸèƒ½ï¼Œæ­¤å¤„ä»…ç»Ÿä¸€æ˜¾ç¤º)
            )
            
            # é¡µæ•°/çˆ¬å–ä¸ªæ•°
            spider_pages = gr.Slider(
                label="çˆ¬å–é¡µæ•°/ä¸ªæ•°", 
                minimum=1, maximum=10, value=3, step=1
            )
            
            # è¿è¡ŒæŒ‰é’®
            spider_btn = gr.Button("ğŸš€ è¿è¡Œé€‰å®šçˆ¬è™«è„šæœ¬", variant="primary")
            
            # è¾“å‡º
            spider_output = gr.Textbox(label="è„šæœ¬ Standard Output/Error", lines=20) 
            
            # æŒ‰é’®ç‚¹å‡»äº‹ä»¶ï¼šè°ƒç”¨é€šç”¨è¿è¡Œå‡½æ•°
            spider_btn.click(
                fn=run_generic_spider_gr, 
                inputs=[spider_choice, spider_kw, spider_sort, spider_pages], 
                outputs=spider_output
            )
            
            # (å¯é€‰) åŠ¨æ€æ›´æ–°é»˜è®¤å€¼å’Œç»„ä»¶å¯è§æ€§
            # å¤æ‚ï¼šä¸ºäº†ç®€åŒ–ï¼Œæˆ‘ä»¬è®©æ‰€æœ‰ç»„ä»¶é»˜è®¤éƒ½æ˜¾ç¤ºï¼Œå¹¶åœ¨é€šç”¨è¿è¡Œå‡½æ•°ä¸­å¤„ç†å‚æ•°çš„å–èˆã€‚
            # å¦‚æœéœ€è¦åŠ¨æ€æ›´æ–°ï¼Œå¯ä»¥æ·»åŠ ä»¥ä¸‹é€»è¾‘ï¼š
            def update_ui_on_script_change(script_name):
                config = SPIDER_CONFIG.get(script_name, {})
                kw = config.get('default_kw', '')
                pages_val = config.get('default_pages', 3)
                sort_vis = True if config.get('sort') else False
                pages_vis = True if config.get('pages') else False
                
                # é’ˆå¯¹ baidu_news_spider.py çš„ç‰¹æ®Šå¤„ç†
                if script_name == "baidu_news_spider.py":
                    pages_vis = False
                
                return (
                    gr.update(value=kw), 
                    gr.update(visible=sort_vis), 
                    gr.update(visible=pages_vis, value=pages_val)
                )

            spider_choice.change(
                fn=update_ui_on_script_change,
                inputs=[spider_choice],
                outputs=[spider_kw, spider_sort, spider_pages]
            )

        # ==============================================
        # 4. æ¨¡å‹æµ‹è¯• (Model Testing)
        # ==============================================
        with gr.TabItem("2. æ¨¡å‹è°ƒè¯•"):
            gr.Markdown(f"## ğŸ§  æ¨¡å‹åŠ è½½ (è·¯å¾„: Program/Models/)")

            # --- è·å–åŠ¨æ€æ¨¡å‹åˆ—è¡¨ ---
            available_models = get_available_models()
            default_model = available_models[0] if available_models else "æœªæ‰¾åˆ°æ¨¡å‹"
            # ------------------------
            model_choice = gr.Radio(
                label="é€‰æ‹©æ¨¡å‹",
                # ä½¿ç”¨åŠ¨æ€è·å–çš„åˆ—è¡¨
                choices=available_models if available_models else ["æœªæ‰¾åˆ°æ¨¡å‹"],
                # é»˜è®¤å€¼è®¾ç½®ä¸ºåˆ—è¡¨çš„ç¬¬ä¸€ä¸ªå…ƒç´ 
                value=default_model,
                # å¦‚æœæ²¡æœ‰æ¨¡å‹ï¼Œç¦ç”¨ Radio æŒ‰é’®
                interactive=bool(available_models) 
            )
            load_btn = gr.Button("åŠ è½½é€‰å®šæ¨¡å‹", variant="primary")
            # UI FIX: ç»Ÿä¸€å¢åŠ è¡Œæ•°
            model_output = gr.Textbox(label="æ¨¡å‹åŠ è½½çŠ¶æ€", lines=10) 

            load_btn.click(
                fn=init_model_and_tokenizer_gr, 
                inputs=[model_choice, state_tokenizer, state_model], 
                outputs=[state_tokenizer, state_model, model_output]
            )

            # --- ä»»åŠ¡æµ‹è¯• ---
            gr.Markdown("## ğŸ’¡ æ¨¡å‹æµ‹è¯•")
            with gr.Tabs():
                
                with gr.TabItem("1. æˆè¯­å¡«ç©º (CHIDF)"):
                    gr.Markdown("### å•æ¡æ¨ç†")
                    chidf_sent = gr.Textbox(label="è¾“å…¥å¥å­", info="è¯·è¾“å…¥å«[MASK]æ ‡è®°çš„å¥å­", value="ä»–é¢å¯¹å›°éš¾æ—¶[MASK]")
                    chidf_cands = gr.Textbox(label="å€™é€‰æˆè¯­", info="ç”¨å…¨è§’é€—å·åˆ†éš”", value="åšæŒä¸æ‡ˆï¼ŒåŠé€”è€ŒåºŸï¼Œæ•·è¡äº†äº‹")
                    chidf_btn = gr.Button("æ‰§è¡Œ CHIDF ä»»åŠ¡", variant="primary")
                    # UI FIX: ç§»é™¤ render_as="html"
                    chidf_output = gr.Textbox(label="ä»»åŠ¡ç»“æœ", lines=15)
                    chidf_btn.click(chidf_task_gr, [state_tokenizer, state_model, chidf_sent, chidf_cands], chidf_output)

                # ä»»åŠ¡ 2: TNEWS (æ–°é—»åˆ†ç±») - åŒ…å«æ‰¹é‡æ¨¡å¼
                with gr.TabItem("2. æ–°é—»åˆ†ç±» (TNEWS)"):
                    tnews_task_state = gr.State("æ–°é—»åˆ†ç±»ï¼ˆTNEWSï¼‰")
                    with gr.Tabs():
                        with gr.TabItem("å•æ¡æ¨ç†"):
                            gr.Markdown("### å•æ¡æ¨ç†")
                            tnews_text = gr.Textbox(label="è¾“å…¥æ–°é—»æ–‡æœ¬", lines=5, value="åˆšåˆšä»æœ‹å‹é‚£é‡Œå¬è¯´ï¼Œç‰¹æ–¯æ‹‰å·²ç»å¼€å§‹åœ¨å›½å†…è¿›è¡Œå¤§è§„æ¨¡çš„é™ä»·ï¼Œä¸çŸ¥é“æ˜¯ä¸æ˜¯çœŸçš„ï¼Œæˆ‘å‡†å¤‡å»ä¹°ä¸€è¾†ã€‚")
                            tnews_btn = gr.Button("æ‰§è¡Œ TNEWS ä»»åŠ¡", variant="primary")
                            # UI FIX: ç»Ÿä¸€å¢åŠ è¡Œæ•°
                            tnews_output = gr.Textbox(label="ä»»åŠ¡ç»“æœ", lines=15)
                            tnews_btn.click(tnews_task_gr, [state_tokenizer, state_model, tnews_text], tnews_output)
                        
                        with gr.TabItem("æ‰¹é‡æµ‹è¯• (CSV)"):
                            # gr.Markdown(f"æ‰¹é‡æ¨¡å¼å°†è¯»å– **`Program/Spiders/Information/News/`** æ–‡ä»¶å¤¹ä¸‹çš„ CSV æ–‡ä»¶ï¼Œå¹¶**æŒ‰åˆ—åï¼ˆ'æ ‡é¢˜'ï¼‰**è¯»å–æ•°æ®ã€‚")
                            
                            tnews_files = gr.Dropdown(
                                label="é€‰æ‹© CSV æ–‡ä»¶", 
                                choices=list_task_csv_files("æ–°é—»åˆ†ç±»ï¼ˆTNEWSï¼‰"), 
                                value=get_initial_file_choice("æ–°é—»åˆ†ç±»ï¼ˆTNEWSï¼‰")
                            )
                            with gr.Row():
                                tnews_batch_preview = gr.Button("1. æ£€æŸ¥æ•°æ®æ–‡ä»¶å¹¶é¢„è§ˆ")
                                tnews_batch_btn = gr.Button("2. ğŸš€ æ‰§è¡Œ TNEWS æ‰¹é‡ä»»åŠ¡ ", variant="primary")
                            refresh_tnews_files = gr.Button("ğŸ”„ åˆ·æ–°æ–‡ä»¶åˆ—è¡¨")

                            # UI FIX: ç§»é™¤ render_as="html"ï¼Œç»Ÿä¸€å¢åŠ è¡Œæ•°
                            tnews_batch_output = gr.Textbox(label="æ‰¹é‡ä»»åŠ¡ç»“æœ ", lines=30) 
                            
                            refresh_tnews_files.click(
                                fn=lambda: gr.update(choices=list_task_csv_files("æ–°é—»åˆ†ç±»ï¼ˆTNEWSï¼‰"), value=get_initial_file_choice("æ–°é—»åˆ†ç±»ï¼ˆTNEWSï¼‰")), 
                                inputs=[], 
                                outputs=tnews_files
                            )
                            tnews_batch_preview.click(read_and_preview_data, [tnews_task_state, tnews_files], tnews_batch_output)
                            tnews_batch_btn.click(tnews_batch_gr, [state_tokenizer, state_model, tnews_files], tnews_batch_output)

                with gr.TabItem("3. è‡ªç„¶è¯­è¨€æ¨ç† (OCNLI)"):
                    gr.Markdown("### å•æ¡æ¨ç†")
                    ocnli_sent1 = gr.Textbox(label="å¥å­1 (å‰æ)", value="äººå·¥æ™ºèƒ½æŠ€æœ¯å‘å±•å¿«")
                    ocnli_sent2 = gr.Textbox(label="å¥å­2 (å‡è®¾)", value="AIæŠ€æœ¯è¿­ä»£å¿«")
                    ocnli_btn = gr.Button("æ‰§è¡Œ OCNLI ä»»åŠ¡", variant="primary")
                    # UI FIX: ç»Ÿä¸€å¢åŠ è¡Œæ•°
                    ocnli_output = gr.Textbox(label="ä»»åŠ¡ç»“æœ", lines=15) 
                    ocnli_btn.click(ocnli_task_gr, [state_tokenizer, state_model, ocnli_sent1, ocnli_sent2], ocnli_output)

                # ä»»åŠ¡ 4: CSL (æ‘˜è¦å…³é”®è¯éªŒè¯) - åŒ…å«æ‰¹é‡æ¨¡å¼
                with gr.TabItem("4. æ‘˜è¦å…³é”®è¯éªŒè¯ (CSL)"):
                    csl_task_state = gr.State("æ‘˜è¦å…³é”®è¯éªŒè¯ï¼ˆCSLï¼‰")
                    with gr.Tabs():
                        with gr.TabItem("å•æ¡æ¨ç†"):
                            gr.Markdown("### å•æ¡æ¨ç†")
                            csl_abstract = gr.Textbox(label="è¾“å…¥æ‘˜è¦", lines=5, value="æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ ç ”ç©¶ä¸­çš„ä¸€ä¸ªæ–°é¢†åŸŸï¼Œè‡´åŠ›äºæ¨¡æ‹Ÿäººè„‘çš„ç¥ç»ç½‘ç»œï¼Œé€šè¿‡å¤šå±‚ç½‘ç»œç»“æ„å®ç°æ•°æ®çš„ç‰¹å¾æå–ã€‚")
                            csl_keywords = gr.Textbox(label="è¾“å…¥å…³é”®è¯", info="ç”¨å…¨è§’é€—å·åˆ†éš”", value="ç¥ç»ç½‘ç»œï¼Œæ·±åº¦å­¦ä¹ ï¼Œç‰¹å¾æå–")
                            csl_btn = gr.Button("æ‰§è¡Œ CSL ä»»åŠ¡", variant="primary")
                            # UI FIX: ç»Ÿä¸€å¢åŠ è¡Œæ•°
                            csl_output = gr.Textbox(label="ä»»åŠ¡ç»“æœ", lines=15) 
                            csl_btn.click(csl_task_gr, [state_tokenizer, state_model, csl_abstract, csl_keywords], csl_output)

                        with gr.TabItem("æ‰¹é‡æµ‹è¯• (CSV)"):
                            # gr.Markdown(f"æ‰¹é‡æ¨¡å¼å°†è¯»å– **`Program/Spiders/Information/Literature/`** æ–‡ä»¶å¤¹ä¸‹çš„ CSV æ–‡ä»¶ï¼Œå¹¶**æŒ‰åˆ—åï¼ˆ'æ‘˜è¦'å’Œ'å…³é”®è¯'ï¼‰**è¯»å–æ•°æ®ã€‚")
                            csl_files = gr.Dropdown(
                                label="é€‰æ‹© CSV æ–‡ä»¶", 
                                choices=list_task_csv_files("æ‘˜è¦å…³é”®è¯éªŒè¯ï¼ˆCSLï¼‰"), 
                                value=get_initial_file_choice("æ‘˜è¦å…³é”®è¯éªŒè¯ï¼ˆCSLï¼‰")
                            )
                            with gr.Row():
                                csl_batch_preview = gr.Button("1. æ£€æŸ¥æ•°æ®æ–‡ä»¶å¹¶é¢„è§ˆ")
                                csl_batch_btn = gr.Button("2. ğŸš€ æ‰§è¡Œ CSL æ‰¹é‡ä»»åŠ¡ ", variant="primary")
                            refresh_csl_files = gr.Button("ğŸ”„ åˆ·æ–°æ–‡ä»¶åˆ—è¡¨")

                            # UI FIX: ç§»é™¤ render_as="html"ï¼Œç»Ÿä¸€å¢åŠ è¡Œæ•°
                            csl_batch_output = gr.Textbox(label="æ‰¹é‡ä»»åŠ¡ç»“æœ ", lines=30) 
                            
                            refresh_csl_files.click(
                                fn=lambda: gr.update(choices=list_task_csv_files("æ‘˜è¦å…³é”®è¯éªŒè¯ï¼ˆCSLï¼‰"), value=get_initial_file_choice("æ‘˜è¦å…³é”®è¯éªŒè¯ï¼ˆCSLï¼‰")), 
                                inputs=[], 
                                outputs=csl_files
                            )
                            csl_batch_preview.click(read_and_preview_data, [csl_task_state, csl_files], csl_batch_output)
                            csl_batch_btn.click(csl_batch_gr, [state_tokenizer, state_model, csl_files], csl_batch_output)

                # ä»»åŠ¡ 5: CSLDCP (ä¸»é¢˜æ–‡çŒ®åˆ†ç±») - åŒ…å«æ‰¹é‡æ¨¡å¼
                with gr.TabItem("5. ä¸»é¢˜æ–‡çŒ®åˆ†ç±» (CSLDCP)"):
                    csldcp_task_state = gr.State("ä¸»é¢˜æ–‡çŒ®åˆ†ç±»ï¼ˆCSLDCPï¼‰")
                    with gr.Tabs():
                        with gr.TabItem("å•æ¡æ¨ç†"):
                            gr.Markdown("### å•æ¡æ¨ç†")
                            csldcp_abstract = gr.Textbox(label="è¾“å…¥æ–‡çŒ®æ‘˜è¦", lines=5, value="æœ¬æ–‡ç ”ç©¶äº†åŸºäºTransformeræ¨¡å‹çš„è‡ªç„¶è¯­è¨€å¤„ç†æŠ€æœ¯åœ¨åŒ»ç–—è¯Šæ–­ç³»ç»Ÿä¸­çš„åº”ç”¨å’Œæ½œåŠ›ã€‚")
                            csldcp_btn = gr.Button("æ‰§è¡Œ CSLDCP ä»»åŠ¡", variant="primary")
                            # UI FIX: ç»Ÿä¸€å¢åŠ è¡Œæ•°
                            csldcp_output = gr.Textbox(label="ä»»åŠ¡ç»“æœ", lines=15) 
                            csldcp_btn.click(csldcp_task_gr, [state_tokenizer, state_model, csldcp_abstract], csldcp_output)
                            
                        with gr.TabItem("æ‰¹é‡æµ‹è¯• (CSV)"):
                            # gr.Markdown(f"æ‰¹é‡æ¨¡å¼å°†è¯»å– **`Program/Spiders/Information/Literature/`** æ–‡ä»¶å¤¹ä¸‹çš„ CSV æ–‡ä»¶ï¼Œå¹¶**æŒ‰åˆ—åï¼ˆ'æ‘˜è¦'ï¼‰**è¯»å–æ•°æ®ã€‚")
                            csldcp_files = gr.Dropdown(
                                label="é€‰æ‹© CSV æ–‡ä»¶", 
                                choices=list_task_csv_files("ä¸»é¢˜æ–‡çŒ®åˆ†ç±»ï¼ˆCSLDCPï¼‰"), 
                                value=get_initial_file_choice("ä¸»é¢˜æ–‡çŒ®åˆ†ç±»ï¼ˆCSLDCPï¼‰")
                            )
                            with gr.Row():
                                csldcp_batch_preview = gr.Button("1. æ£€æŸ¥æ•°æ®æ–‡ä»¶å¹¶é¢„è§ˆ")
                                csldcp_batch_btn = gr.Button("2. ğŸš€ æ‰§è¡Œ CSLDCP æ‰¹é‡ä»»åŠ¡ ", variant="primary")
                            refresh_csldcp_files = gr.Button("ğŸ”„ åˆ·æ–°æ–‡ä»¶åˆ—è¡¨")

                            # UI FIX: ç§»é™¤ render_as="html"ï¼Œç»Ÿä¸€å¢åŠ è¡Œæ•°
                            csldcp_batch_output = gr.Textbox(label="æ‰¹é‡ä»»åŠ¡ç»“æœ ", lines=30) 
                            
                            refresh_csldcp_files.click(
                                fn=lambda: gr.update(choices=list_task_csv_files("ä¸»é¢˜æ–‡çŒ®åˆ†ç±»ï¼ˆCSLDCPï¼‰"), value=get_initial_file_choice("ä¸»é¢˜æ–‡çŒ®åˆ†ç±»ï¼ˆCSLDCPï¼‰")), 
                                inputs=[], 
                                outputs=csldcp_files
                            )
                            csldcp_batch_preview.click(read_and_preview_data, [csldcp_task_state, csldcp_files], csldcp_batch_output)
                            csldcp_batch_btn.click(csldcp_batch_gr, [state_tokenizer, state_model, csldcp_files], csldcp_batch_output)

                # ä»»åŠ¡ 6: IFLYTEK (åº”ç”¨æè¿°åˆ†ç±») - åŒ…å«æ‰¹é‡æ¨¡å¼
                with gr.TabItem("6. åº”ç”¨æè¿°åˆ†ç±» (IFLYTEK)"):
                    iflytek_task_state = gr.State("åº”ç”¨æè¿°åˆ†ç±»ï¼ˆIFLYTEKï¼‰")
                    with gr.Tabs():
                        with gr.TabItem("å•æ¡æ¨ç†"):
                            gr.Markdown("### å•æ¡æ¨ç†")
                            iflytek_desc = gr.Textbox(label="è¾“å…¥åº”ç”¨æè¿°", lines=5, value="ä¸€ä¸ªåŠŸèƒ½å¼ºå¤§çš„å›¾ç‰‡ç¼–è¾‘å™¨ï¼ŒåŒ…å«æ»¤é•œã€è£å‰ªã€ç¾é¢œç­‰å¤šç§åŠŸèƒ½ï¼Œè®©ä½ çš„ç…§ç‰‡ç„•ç„¶ä¸€æ–°ã€‚")
                            iflytek_btn = gr.Button("æ‰§è¡Œ IFLYTEK ä»»åŠ¡", variant="primary")
                            # UI FIX: ç»Ÿä¸€å¢åŠ è¡Œæ•°
                            iflytek_output = gr.Textbox(label="ä»»åŠ¡ç»“æœ", lines=15) 
                            iflytek_btn.click(iflytek_task_gr, [state_tokenizer, state_model, iflytek_desc], iflytek_output)

                        with gr.TabItem("æ‰¹é‡æµ‹è¯• (CSV)"):
                            # gr.Markdown(f"æ‰¹é‡æ¨¡å¼å°†è¯»å– **`Program/Spiders/Information/AppDescriptions/`** æ–‡ä»¶å¤¹ä¸‹çš„ CSV æ–‡ä»¶ï¼Œå¹¶**æŒ‰åˆ—åï¼ˆ'åº”ç”¨ç®€ä»‹'ï¼‰**è¯»å–æ•°æ®ã€‚")
                            iflytek_files = gr.Dropdown(
                                label="é€‰æ‹© CSV æ–‡ä»¶", 
                                choices=list_task_csv_files("åº”ç”¨æè¿°åˆ†ç±»ï¼ˆIFLYTEKï¼‰"), 
                                value=get_initial_file_choice("åº”ç”¨æè¿°åˆ†ç±»ï¼ˆIFLYTEKï¼‰")
                            )
                            with gr.Row():
                                iflytek_batch_preview = gr.Button("1. æ£€æŸ¥æ•°æ®æ–‡ä»¶å¹¶é¢„è§ˆ")
                                iflytek_batch_btn = gr.Button("2. ğŸš€ æ‰§è¡Œ IFLYTEK æ‰¹é‡ä»»åŠ¡ ", variant="primary")
                            refresh_iflytek_files = gr.Button("ğŸ”„ åˆ·æ–°æ–‡ä»¶åˆ—è¡¨")

                            # UI FIX: ç§»é™¤ render_as="html"ï¼Œç»Ÿä¸€å¢åŠ è¡Œæ•°
                            iflytek_batch_output = gr.Textbox(label="æ‰¹é‡ä»»åŠ¡ç»“æœ ", lines=30) 
                            
                            refresh_iflytek_files.click(
                                fn=lambda: gr.update(choices=list_task_csv_files("åº”ç”¨æè¿°åˆ†ç±»ï¼ˆIFLYTEKï¼‰"), value=get_initial_file_choice("åº”ç”¨æè¿°åˆ†ç±»ï¼ˆIFLYTEKï¼‰")),
                                inputs=[], 
                                outputs=iflytek_files
                            )
                            iflytek_batch_preview.click(read_and_preview_data, [iflytek_task_state, iflytek_files], iflytek_batch_output)
                            iflytek_batch_btn.click(iflytek_batch_gr, [state_tokenizer, state_model, iflytek_files], iflytek_batch_output)

                with gr.TabItem("7. æŒ‡ä»£æ¶ˆè§£ (CLUEWSC)"):
                    gr.Markdown("### å•æ¡æ¨ç†")
                    cluewsc_sent = gr.Textbox(label="è¾“å…¥å¥å­", value="å°æ˜å¯¹ä»–çš„åŒå­¦è¯´ï¼Œæ˜å¤©ä»–ä¼šå»å›¾ä¹¦é¦†ã€‚")
                    cluewsc_word = gr.Textbox(label="æŒ‡ä»£è¯", value="ä»–")
                    cluewsc_pos = gr.Number(label="æŒ‡ä»£è¯ä½ç½®", value=4, precision=0, visible=False) 
                    cluewsc_btn = gr.Button("æ‰§è¡Œ CLUEWSC ä»»åŠ¡", variant="primary")
                    # UI FIX: ç»Ÿä¸€å¢åŠ è¡Œæ•°
                    cluewsc_output = gr.Textbox(label="ä»»åŠ¡ç»“æœ", lines=15) 
                    cluewsc_btn.click(cluewsc_task_gr, [state_tokenizer, state_model, cluewsc_sent, cluewsc_word, cluewsc_pos], cluewsc_output)
    
if __name__ == "__main__":
    try:
        print("\nğŸš€ WebUIæ­£åœ¨å¯åŠ¨ï¼Œè¯·ç­‰å¾…æµè§ˆå™¨è‡ªåŠ¨æ‰“å¼€...")
        # ä½¿ç”¨å¤šçº¿ç¨‹ï¼Œè®©æç¤ºä¿¡æ¯åœ¨åå°ç­‰å¾… Gradio å®Œæˆå¯åŠ¨æ—¥å¿—è¾“å‡º
        import threading
        def print_tip():
            # å»¶è¿Ÿ 3 ç§’ï¼Œç¡®ä¿ Gradio çš„ URL ä¿¡æ¯å·²ç»è¾“å‡º
            time.sleep(3) 
            print("\nğŸ’¡ æ‚¨å¯ä»¥éšæ—¶åœ¨ç»ˆç«¯æŒ‰ä¸‹Ctrl+Cå¿«æ·é”®ï¼Œä»¥ç»ˆæ­¢WebUI")
        threading.Thread(target=print_tip, daemon=True).start()

        # å¯åŠ¨ Gradioï¼Œæ­¤æ—¶ä¸»çº¿ç¨‹é˜»å¡
        demo.launch(inbrowser=True)

    except KeyboardInterrupt:
        # æ•è· Ctrl+C ä¿¡å·
        print("\nğŸ‘‹ æ¥æ”¶åˆ°å…³é—­ä¿¡å·ï¼Œæ­£åœ¨ä¼˜é›…åœ°å…³é—­WebUI...")
        pass
    except Exception as e:
        print(f"\n\nâŒ WebUIè¿è¡Œè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
    else:
        # å¦‚æœæ²¡æœ‰å¼‚å¸¸ï¼ˆå³ç¨‹åºæ­£å¸¸é€€å‡º launch()ï¼‰
        # åœ¨ Gradio åœºæ™¯ä¸‹ï¼Œè¿™é‡Œé€šå¸¸ä¸ä¼šè¢«æ‰§è¡Œï¼Œä½†åœ¨æŸäº›æƒ…å†µä¸‹æ˜¯ä¿é™©æªæ–½
        print("\nğŸ‘‹ æ¥æ”¶åˆ°å…³é—­ä¿¡å·ï¼Œæ­£åœ¨ä¼˜é›…åœ°å…³é—­WebUI...")